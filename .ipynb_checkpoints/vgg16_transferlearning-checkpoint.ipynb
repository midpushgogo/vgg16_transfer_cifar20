{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg16对cifar-10的迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import vgg16\n",
    "import utils\n",
    "import pickle\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img):\n",
    "    # load image\n",
    "    img = img.reshape(3, 32, 32)\n",
    "    img = img.transpose(1,2,0)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    resized_img = resized_img.reshape((1,224, 224, 3))\n",
    "\n",
    "    return resized_img\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "D:\\Soft\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# cifar文件放在当前目录下\n",
    "fil=unpickle('test_batch')\n",
    "data=fil[b'data']\n",
    "labels=fil[b'labels'][:5000]\n",
    "batch=()\n",
    "for i in range(5000):\n",
    "    p=load_image(data[i])\n",
    "    batch=batch + (p,)\n",
    "batch = np.concatenate(batch, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将cifar的每一张图片用vgg的卷积层转换为4096\\*1的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\Desktop\\vgg\\tensorflow-vgg\\vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 3s\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor x in get_batches_for_x(batch):\\n        feed_dict = {input_: x}\\n        codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\\n        if codes is None:\\n            codes = codes_batch\\n        else:\\n            codes = np.concatenate((codes, codes_batch))\\n        print('one turn!')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes=None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(\"float\", [None,224, 224, 3])\n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    turn=len(batch)//64\n",
    "    for i in range(turn+1):\n",
    "        if i==turn:\n",
    "            feed_dict = {input_: batch[turn*64:]}\n",
    "        else:\n",
    "            feed_dict = {input_: batch[i*64:i*64+64]}\n",
    "        codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "        if codes is None:\n",
    "                codes = codes_batch\n",
    "        else:\n",
    "                codes = np.concatenate((codes, codes_batch))\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (3993, 4096) (3993, 10)\n",
      "Validation shapes (x, y): (499, 4096) (499, 10)\n",
      "Test shapes (x, y): (500, 4096) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "with open('codes', 'w') as f:\n",
    "    codes.tofile(f)\n",
    "    \n",
    "import csv\n",
    "with open('labels', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\n')\n",
    "    writer.writerow(labels)\n",
    "    \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "\n",
    "labels_vecs = lb.transform(labels)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "\n",
    "train_idx, val_idx = next(ss.split(codes, labels))\n",
    "\n",
    "half_val_len = int(len(val_idx)/2)\n",
    "val_idx, test_idx = val_idx[:half_val_len], val_idx[half_val_len:]\n",
    "\n",
    "train_x, train_y = codes[train_idx], labels_vecs[train_idx]\n",
    "val_x, val_y = codes[val_idx], labels_vecs[val_idx]\n",
    "test_x, test_y = codes[test_idx], labels_vecs[test_idx]\n",
    "\n",
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-17-8fd691f9c627>:13: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 输入数据的维度\n",
    "inputs_ = tf.placeholder(tf.float32, shape=[None, codes.shape[1]])\n",
    "# 标签数据的维度\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, labels_vecs.shape[1]])\n",
    "\n",
    "# 加入一个256维的全连接的层\n",
    "fc = tf.contrib.layers.fully_connected(inputs_, 256)\n",
    "\n",
    "# 加入一个10维的全连接层\n",
    "logits = tf.contrib.layers.fully_connected(fc, labels_vecs.shape[1], activation_fn=None)\n",
    "\n",
    "# 计算cross entropy值\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "\n",
    "# 计算损失函数\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 采用用得最广泛的AdamOptimizer优化器\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# 得到最后的预测分布\n",
    "predicted = tf.nn.softmax(logits)\n",
    "\n",
    "# 计算准确度\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练添加的全连接层网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" 这是一个生成器函数，按照n_batches的大小将数据划分了小块 \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # 如果不是最后一个batch，那么这个batch中应该有batch_size个数据\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # 否则的话，那剩余的不够batch_size的数据都凑入到一个batch中\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # 生成器语法，返回X和Y\n",
    "        yield X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Iteration: 0 Training loss: 4.54140\n",
      "Epoch: 1/100 Iteration: 1 Training loss: 5.77719\n",
      "Epoch: 1/100 Iteration: 2 Training loss: 6.52939\n",
      "Epoch: 1/100 Iteration: 3 Training loss: 8.52608\n",
      "Epoch: 1/100 Iteration: 4 Training loss: 7.31165\n",
      "Epoch: 0/100 Iteration: 5 Validation Acc: 0.4990\n",
      "Epoch: 1/100 Iteration: 5 Training loss: 5.52604\n",
      "Epoch: 1/100 Iteration: 6 Training loss: 5.32081\n",
      "Epoch: 1/100 Iteration: 7 Training loss: 4.15429\n",
      "Epoch: 1/100 Iteration: 8 Training loss: 2.53710\n",
      "Epoch: 1/100 Iteration: 9 Training loss: 1.79610\n",
      "Epoch: 0/100 Iteration: 10 Validation Acc: 0.6232\n",
      "Epoch: 2/100 Iteration: 10 Training loss: 0.79379\n",
      "Epoch: 2/100 Iteration: 11 Training loss: 0.86459\n",
      "Epoch: 2/100 Iteration: 12 Training loss: 1.28435\n",
      "Epoch: 2/100 Iteration: 13 Training loss: 1.39403\n",
      "Epoch: 2/100 Iteration: 14 Training loss: 1.36121\n",
      "Epoch: 1/100 Iteration: 15 Validation Acc: 0.5812\n",
      "Epoch: 2/100 Iteration: 15 Training loss: 1.28178\n",
      "Epoch: 2/100 Iteration: 16 Training loss: 1.20269\n",
      "Epoch: 2/100 Iteration: 17 Training loss: 0.92425\n",
      "Epoch: 2/100 Iteration: 18 Training loss: 0.78083\n",
      "Epoch: 2/100 Iteration: 19 Training loss: 0.88919\n",
      "Epoch: 1/100 Iteration: 20 Validation Acc: 0.7074\n",
      "Epoch: 3/100 Iteration: 20 Training loss: 0.61916\n",
      "Epoch: 3/100 Iteration: 21 Training loss: 0.59744\n",
      "Epoch: 3/100 Iteration: 22 Training loss: 0.71076\n",
      "Epoch: 3/100 Iteration: 23 Training loss: 0.78598\n",
      "Epoch: 3/100 Iteration: 24 Training loss: 0.75731\n",
      "Epoch: 2/100 Iteration: 25 Validation Acc: 0.7114\n",
      "Epoch: 3/100 Iteration: 25 Training loss: 0.60892\n",
      "Epoch: 3/100 Iteration: 26 Training loss: 0.82465\n",
      "Epoch: 3/100 Iteration: 27 Training loss: 0.64639\n",
      "Epoch: 3/100 Iteration: 28 Training loss: 0.57183\n",
      "Epoch: 3/100 Iteration: 29 Training loss: 0.57969\n",
      "Epoch: 2/100 Iteration: 30 Validation Acc: 0.7575\n",
      "Epoch: 4/100 Iteration: 30 Training loss: 0.42688\n",
      "Epoch: 4/100 Iteration: 31 Training loss: 0.43361\n",
      "Epoch: 4/100 Iteration: 32 Training loss: 0.50256\n",
      "Epoch: 4/100 Iteration: 33 Training loss: 0.51979\n",
      "Epoch: 4/100 Iteration: 34 Training loss: 0.46279\n",
      "Epoch: 3/100 Iteration: 35 Validation Acc: 0.7475\n",
      "Epoch: 4/100 Iteration: 35 Training loss: 0.49093\n",
      "Epoch: 4/100 Iteration: 36 Training loss: 0.67590\n",
      "Epoch: 4/100 Iteration: 37 Training loss: 0.48987\n",
      "Epoch: 4/100 Iteration: 38 Training loss: 0.48473\n",
      "Epoch: 4/100 Iteration: 39 Training loss: 0.47850\n",
      "Epoch: 3/100 Iteration: 40 Validation Acc: 0.7675\n",
      "Epoch: 5/100 Iteration: 40 Training loss: 0.33052\n",
      "Epoch: 5/100 Iteration: 41 Training loss: 0.31600\n",
      "Epoch: 5/100 Iteration: 42 Training loss: 0.40795\n",
      "Epoch: 5/100 Iteration: 43 Training loss: 0.41929\n",
      "Epoch: 5/100 Iteration: 44 Training loss: 0.39667\n",
      "Epoch: 4/100 Iteration: 45 Validation Acc: 0.7896\n",
      "Epoch: 5/100 Iteration: 45 Training loss: 0.40056\n",
      "Epoch: 5/100 Iteration: 46 Training loss: 0.51327\n",
      "Epoch: 5/100 Iteration: 47 Training loss: 0.37190\n",
      "Epoch: 5/100 Iteration: 48 Training loss: 0.37658\n",
      "Epoch: 5/100 Iteration: 49 Training loss: 0.38860\n",
      "Epoch: 4/100 Iteration: 50 Validation Acc: 0.7796\n",
      "Epoch: 6/100 Iteration: 50 Training loss: 0.25790\n",
      "Epoch: 6/100 Iteration: 51 Training loss: 0.24166\n",
      "Epoch: 6/100 Iteration: 52 Training loss: 0.30527\n",
      "Epoch: 6/100 Iteration: 53 Training loss: 0.33423\n",
      "Epoch: 6/100 Iteration: 54 Training loss: 0.34756\n",
      "Epoch: 5/100 Iteration: 55 Validation Acc: 0.7695\n",
      "Epoch: 6/100 Iteration: 55 Training loss: 0.34650\n",
      "Epoch: 6/100 Iteration: 56 Training loss: 0.42133\n",
      "Epoch: 6/100 Iteration: 57 Training loss: 0.28599\n",
      "Epoch: 6/100 Iteration: 58 Training loss: 0.27111\n",
      "Epoch: 6/100 Iteration: 59 Training loss: 0.28645\n",
      "Epoch: 5/100 Iteration: 60 Validation Acc: 0.7756\n",
      "Epoch: 7/100 Iteration: 60 Training loss: 0.22165\n",
      "Epoch: 7/100 Iteration: 61 Training loss: 0.21702\n",
      "Epoch: 7/100 Iteration: 62 Training loss: 0.25670\n",
      "Epoch: 7/100 Iteration: 63 Training loss: 0.24962\n",
      "Epoch: 7/100 Iteration: 64 Training loss: 0.24411\n",
      "Epoch: 6/100 Iteration: 65 Validation Acc: 0.7796\n",
      "Epoch: 7/100 Iteration: 65 Training loss: 0.28339\n",
      "Epoch: 7/100 Iteration: 66 Training loss: 0.33336\n",
      "Epoch: 7/100 Iteration: 67 Training loss: 0.25538\n",
      "Epoch: 7/100 Iteration: 68 Training loss: 0.21326\n",
      "Epoch: 7/100 Iteration: 69 Training loss: 0.22047\n",
      "Epoch: 6/100 Iteration: 70 Validation Acc: 0.7896\n",
      "Epoch: 8/100 Iteration: 70 Training loss: 0.16792\n",
      "Epoch: 8/100 Iteration: 71 Training loss: 0.17185\n",
      "Epoch: 8/100 Iteration: 72 Training loss: 0.22226\n",
      "Epoch: 8/100 Iteration: 73 Training loss: 0.21609\n",
      "Epoch: 8/100 Iteration: 74 Training loss: 0.18911\n",
      "Epoch: 7/100 Iteration: 75 Validation Acc: 0.7916\n",
      "Epoch: 8/100 Iteration: 75 Training loss: 0.20689\n",
      "Epoch: 8/100 Iteration: 76 Training loss: 0.25342\n",
      "Epoch: 8/100 Iteration: 77 Training loss: 0.21213\n",
      "Epoch: 8/100 Iteration: 78 Training loss: 0.18925\n",
      "Epoch: 8/100 Iteration: 79 Training loss: 0.19106\n",
      "Epoch: 7/100 Iteration: 80 Validation Acc: 0.7936\n",
      "Epoch: 9/100 Iteration: 80 Training loss: 0.13267\n",
      "Epoch: 9/100 Iteration: 81 Training loss: 0.12627\n",
      "Epoch: 9/100 Iteration: 82 Training loss: 0.16993\n",
      "Epoch: 9/100 Iteration: 83 Training loss: 0.18963\n",
      "Epoch: 9/100 Iteration: 84 Training loss: 0.16398\n",
      "Epoch: 8/100 Iteration: 85 Validation Acc: 0.8056\n",
      "Epoch: 9/100 Iteration: 85 Training loss: 0.16872\n",
      "Epoch: 9/100 Iteration: 86 Training loss: 0.20018\n",
      "Epoch: 9/100 Iteration: 87 Training loss: 0.15463\n",
      "Epoch: 9/100 Iteration: 88 Training loss: 0.15186\n",
      "Epoch: 9/100 Iteration: 89 Training loss: 0.17497\n",
      "Epoch: 8/100 Iteration: 90 Validation Acc: 0.7796\n",
      "Epoch: 10/100 Iteration: 90 Training loss: 0.12784\n",
      "Epoch: 10/100 Iteration: 91 Training loss: 0.10234\n",
      "Epoch: 10/100 Iteration: 92 Training loss: 0.12557\n",
      "Epoch: 10/100 Iteration: 93 Training loss: 0.13858\n",
      "Epoch: 10/100 Iteration: 94 Training loss: 0.13683\n",
      "Epoch: 9/100 Iteration: 95 Validation Acc: 0.8036\n",
      "Epoch: 10/100 Iteration: 95 Training loss: 0.14921\n",
      "Epoch: 10/100 Iteration: 96 Training loss: 0.18233\n",
      "Epoch: 10/100 Iteration: 97 Training loss: 0.12014\n",
      "Epoch: 10/100 Iteration: 98 Training loss: 0.11779\n",
      "Epoch: 10/100 Iteration: 99 Training loss: 0.13240\n",
      "Epoch: 9/100 Iteration: 100 Validation Acc: 0.7836\n",
      "Epoch: 11/100 Iteration: 100 Training loss: 0.10915\n",
      "Epoch: 11/100 Iteration: 101 Training loss: 0.10285\n",
      "Epoch: 11/100 Iteration: 102 Training loss: 0.12122\n",
      "Epoch: 11/100 Iteration: 103 Training loss: 0.11564\n",
      "Epoch: 11/100 Iteration: 104 Training loss: 0.10294\n",
      "Epoch: 10/100 Iteration: 105 Validation Acc: 0.7916\n",
      "Epoch: 11/100 Iteration: 105 Training loss: 0.11724\n",
      "Epoch: 11/100 Iteration: 106 Training loss: 0.15673\n",
      "Epoch: 11/100 Iteration: 107 Training loss: 0.11434\n",
      "Epoch: 11/100 Iteration: 108 Training loss: 0.12117\n",
      "Epoch: 11/100 Iteration: 109 Training loss: 0.10323\n",
      "Epoch: 10/100 Iteration: 110 Validation Acc: 0.7856\n",
      "Epoch: 12/100 Iteration: 110 Training loss: 0.08134\n",
      "Epoch: 12/100 Iteration: 111 Training loss: 0.08680\n",
      "Epoch: 12/100 Iteration: 112 Training loss: 0.11690\n",
      "Epoch: 12/100 Iteration: 113 Training loss: 0.12408\n",
      "Epoch: 12/100 Iteration: 114 Training loss: 0.10411\n",
      "Epoch: 11/100 Iteration: 115 Validation Acc: 0.8056\n",
      "Epoch: 12/100 Iteration: 115 Training loss: 0.09436\n",
      "Epoch: 12/100 Iteration: 116 Training loss: 0.11858\n",
      "Epoch: 12/100 Iteration: 117 Training loss: 0.10786\n",
      "Epoch: 12/100 Iteration: 118 Training loss: 0.14877\n",
      "Epoch: 12/100 Iteration: 119 Training loss: 0.11289\n",
      "Epoch: 11/100 Iteration: 120 Validation Acc: 0.7876\n",
      "Epoch: 13/100 Iteration: 120 Training loss: 0.07046\n",
      "Epoch: 13/100 Iteration: 121 Training loss: 0.07157\n",
      "Epoch: 13/100 Iteration: 122 Training loss: 0.10623\n",
      "Epoch: 13/100 Iteration: 123 Training loss: 0.11776\n",
      "Epoch: 13/100 Iteration: 124 Training loss: 0.11227\n",
      "Epoch: 12/100 Iteration: 125 Validation Acc: 0.7876\n",
      "Epoch: 13/100 Iteration: 125 Training loss: 0.09981\n",
      "Epoch: 13/100 Iteration: 126 Training loss: 0.11357\n",
      "Epoch: 13/100 Iteration: 127 Training loss: 0.09087\n",
      "Epoch: 13/100 Iteration: 128 Training loss: 0.12707\n",
      "Epoch: 13/100 Iteration: 129 Training loss: 0.11699\n",
      "Epoch: 12/100 Iteration: 130 Validation Acc: 0.7876\n",
      "Epoch: 14/100 Iteration: 130 Training loss: 0.08117\n",
      "Epoch: 14/100 Iteration: 131 Training loss: 0.07545\n",
      "Epoch: 14/100 Iteration: 132 Training loss: 0.08807\n",
      "Epoch: 14/100 Iteration: 133 Training loss: 0.08951\n",
      "Epoch: 14/100 Iteration: 134 Training loss: 0.08333\n",
      "Epoch: 13/100 Iteration: 135 Validation Acc: 0.7796\n",
      "Epoch: 14/100 Iteration: 135 Training loss: 0.09784\n",
      "Epoch: 14/100 Iteration: 136 Training loss: 0.12701\n",
      "Epoch: 14/100 Iteration: 137 Training loss: 0.09942\n",
      "Epoch: 14/100 Iteration: 138 Training loss: 0.08370\n",
      "Epoch: 14/100 Iteration: 139 Training loss: 0.08101\n",
      "Epoch: 13/100 Iteration: 140 Validation Acc: 0.7776\n",
      "Epoch: 15/100 Iteration: 140 Training loss: 0.07645\n",
      "Epoch: 15/100 Iteration: 141 Training loss: 0.08983\n",
      "Epoch: 15/100 Iteration: 142 Training loss: 0.09116\n",
      "Epoch: 15/100 Iteration: 143 Training loss: 0.08770\n",
      "Epoch: 15/100 Iteration: 144 Training loss: 0.06765\n",
      "Epoch: 14/100 Iteration: 145 Validation Acc: 0.7956\n",
      "Epoch: 15/100 Iteration: 145 Training loss: 0.06285\n",
      "Epoch: 15/100 Iteration: 146 Training loss: 0.09811\n",
      "Epoch: 15/100 Iteration: 147 Training loss: 0.08953\n",
      "Epoch: 15/100 Iteration: 148 Training loss: 0.10492\n",
      "Epoch: 15/100 Iteration: 149 Training loss: 0.09177\n",
      "Epoch: 14/100 Iteration: 150 Validation Acc: 0.7756\n",
      "Epoch: 16/100 Iteration: 150 Training loss: 0.06235\n",
      "Epoch: 16/100 Iteration: 151 Training loss: 0.07485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 Iteration: 152 Training loss: 0.07581\n",
      "Epoch: 16/100 Iteration: 153 Training loss: 0.08277\n",
      "Epoch: 16/100 Iteration: 154 Training loss: 0.07821\n",
      "Epoch: 15/100 Iteration: 155 Validation Acc: 0.7936\n",
      "Epoch: 16/100 Iteration: 155 Training loss: 0.07891\n",
      "Epoch: 16/100 Iteration: 156 Training loss: 0.10431\n",
      "Epoch: 16/100 Iteration: 157 Training loss: 0.05541\n",
      "Epoch: 16/100 Iteration: 158 Training loss: 0.06253\n",
      "Epoch: 16/100 Iteration: 159 Training loss: 0.08634\n",
      "Epoch: 15/100 Iteration: 160 Validation Acc: 0.7735\n",
      "Epoch: 17/100 Iteration: 160 Training loss: 0.07726\n",
      "Epoch: 17/100 Iteration: 161 Training loss: 0.09466\n",
      "Epoch: 17/100 Iteration: 162 Training loss: 0.05601\n",
      "Epoch: 17/100 Iteration: 163 Training loss: 0.04807\n",
      "Epoch: 17/100 Iteration: 164 Training loss: 0.05719\n",
      "Epoch: 16/100 Iteration: 165 Validation Acc: 0.7896\n",
      "Epoch: 17/100 Iteration: 165 Training loss: 0.07346\n",
      "Epoch: 17/100 Iteration: 166 Training loss: 0.13227\n",
      "Epoch: 17/100 Iteration: 167 Training loss: 0.07627\n",
      "Epoch: 17/100 Iteration: 168 Training loss: 0.05940\n",
      "Epoch: 17/100 Iteration: 169 Training loss: 0.05173\n",
      "Epoch: 16/100 Iteration: 170 Validation Acc: 0.7756\n",
      "Epoch: 18/100 Iteration: 170 Training loss: 0.05787\n",
      "Epoch: 18/100 Iteration: 171 Training loss: 0.10854\n",
      "Epoch: 18/100 Iteration: 172 Training loss: 0.09616\n",
      "Epoch: 18/100 Iteration: 173 Training loss: 0.06897\n",
      "Epoch: 18/100 Iteration: 174 Training loss: 0.03728\n",
      "Epoch: 17/100 Iteration: 175 Validation Acc: 0.7976\n",
      "Epoch: 18/100 Iteration: 175 Training loss: 0.04670\n",
      "Epoch: 18/100 Iteration: 176 Training loss: 0.12614\n",
      "Epoch: 18/100 Iteration: 177 Training loss: 0.11009\n",
      "Epoch: 18/100 Iteration: 178 Training loss: 0.09097\n",
      "Epoch: 18/100 Iteration: 179 Training loss: 0.04531\n",
      "Epoch: 17/100 Iteration: 180 Validation Acc: 0.7735\n",
      "Epoch: 19/100 Iteration: 180 Training loss: 0.03560\n",
      "Epoch: 19/100 Iteration: 181 Training loss: 0.07393\n",
      "Epoch: 19/100 Iteration: 182 Training loss: 0.11968\n",
      "Epoch: 19/100 Iteration: 183 Training loss: 0.11405\n",
      "Epoch: 19/100 Iteration: 184 Training loss: 0.05287\n",
      "Epoch: 18/100 Iteration: 185 Validation Acc: 0.8016\n",
      "Epoch: 19/100 Iteration: 185 Training loss: 0.03827\n",
      "Epoch: 19/100 Iteration: 186 Training loss: 0.08748\n",
      "Epoch: 19/100 Iteration: 187 Training loss: 0.10512\n",
      "Epoch: 19/100 Iteration: 188 Training loss: 0.14727\n",
      "Epoch: 19/100 Iteration: 189 Training loss: 0.07668\n",
      "Epoch: 18/100 Iteration: 190 Validation Acc: 0.7836\n",
      "Epoch: 20/100 Iteration: 190 Training loss: 0.03611\n",
      "Epoch: 20/100 Iteration: 191 Training loss: 0.04490\n",
      "Epoch: 20/100 Iteration: 192 Training loss: 0.10077\n",
      "Epoch: 20/100 Iteration: 193 Training loss: 0.14165\n",
      "Epoch: 20/100 Iteration: 194 Training loss: 0.10281\n",
      "Epoch: 19/100 Iteration: 195 Validation Acc: 0.7836\n",
      "Epoch: 20/100 Iteration: 195 Training loss: 0.06469\n",
      "Epoch: 20/100 Iteration: 196 Training loss: 0.07186\n",
      "Epoch: 20/100 Iteration: 197 Training loss: 0.08596\n",
      "Epoch: 20/100 Iteration: 198 Training loss: 0.16567\n",
      "Epoch: 20/100 Iteration: 199 Training loss: 0.12758\n",
      "Epoch: 19/100 Iteration: 200 Validation Acc: 0.7816\n",
      "Epoch: 21/100 Iteration: 200 Training loss: 0.06704\n",
      "Epoch: 21/100 Iteration: 201 Training loss: 0.04614\n",
      "Epoch: 21/100 Iteration: 202 Training loss: 0.07966\n",
      "Epoch: 21/100 Iteration: 203 Training loss: 0.12216\n",
      "Epoch: 21/100 Iteration: 204 Training loss: 0.11557\n",
      "Epoch: 20/100 Iteration: 205 Validation Acc: 0.7836\n",
      "Epoch: 21/100 Iteration: 205 Training loss: 0.06471\n",
      "Epoch: 21/100 Iteration: 206 Training loss: 0.06833\n",
      "Epoch: 21/100 Iteration: 207 Training loss: 0.06548\n",
      "Epoch: 21/100 Iteration: 208 Training loss: 0.15728\n",
      "Epoch: 21/100 Iteration: 209 Training loss: 0.12195\n",
      "Epoch: 20/100 Iteration: 210 Validation Acc: 0.8016\n",
      "Epoch: 22/100 Iteration: 210 Training loss: 0.05643\n",
      "Epoch: 22/100 Iteration: 211 Training loss: 0.05482\n",
      "Epoch: 22/100 Iteration: 212 Training loss: 0.10370\n",
      "Epoch: 22/100 Iteration: 213 Training loss: 0.12566\n",
      "Epoch: 22/100 Iteration: 214 Training loss: 0.13619\n",
      "Epoch: 21/100 Iteration: 215 Validation Acc: 0.7976\n",
      "Epoch: 22/100 Iteration: 215 Training loss: 0.07401\n",
      "Epoch: 22/100 Iteration: 216 Training loss: 0.06430\n",
      "Epoch: 22/100 Iteration: 217 Training loss: 0.06475\n",
      "Epoch: 22/100 Iteration: 218 Training loss: 0.17376\n",
      "Epoch: 22/100 Iteration: 219 Training loss: 0.16932\n",
      "Epoch: 21/100 Iteration: 220 Validation Acc: 0.7856\n",
      "Epoch: 23/100 Iteration: 220 Training loss: 0.06747\n",
      "Epoch: 23/100 Iteration: 221 Training loss: 0.05616\n",
      "Epoch: 23/100 Iteration: 222 Training loss: 0.05349\n",
      "Epoch: 23/100 Iteration: 223 Training loss: 0.11775\n",
      "Epoch: 23/100 Iteration: 224 Training loss: 0.14977\n",
      "Epoch: 22/100 Iteration: 225 Validation Acc: 0.7535\n",
      "Epoch: 23/100 Iteration: 225 Training loss: 0.13552\n",
      "Epoch: 23/100 Iteration: 226 Training loss: 0.12907\n",
      "Epoch: 23/100 Iteration: 227 Training loss: 0.05184\n",
      "Epoch: 23/100 Iteration: 228 Training loss: 0.05323\n",
      "Epoch: 23/100 Iteration: 229 Training loss: 0.12711\n",
      "Epoch: 22/100 Iteration: 230 Validation Acc: 0.7735\n",
      "Epoch: 24/100 Iteration: 230 Training loss: 0.11521\n",
      "Epoch: 24/100 Iteration: 231 Training loss: 0.12560\n",
      "Epoch: 24/100 Iteration: 232 Training loss: 0.06808\n",
      "Epoch: 24/100 Iteration: 233 Training loss: 0.06360\n",
      "Epoch: 24/100 Iteration: 234 Training loss: 0.07754\n",
      "Epoch: 23/100 Iteration: 235 Validation Acc: 0.7535\n",
      "Epoch: 24/100 Iteration: 235 Training loss: 0.10317\n",
      "Epoch: 24/100 Iteration: 236 Training loss: 0.20219\n",
      "Epoch: 24/100 Iteration: 237 Training loss: 0.13764\n",
      "Epoch: 24/100 Iteration: 238 Training loss: 0.05818\n",
      "Epoch: 24/100 Iteration: 239 Training loss: 0.05047\n",
      "Epoch: 23/100 Iteration: 240 Validation Acc: 0.7876\n",
      "Epoch: 25/100 Iteration: 240 Training loss: 0.09390\n",
      "Epoch: 25/100 Iteration: 241 Training loss: 0.13821\n",
      "Epoch: 25/100 Iteration: 242 Training loss: 0.13869\n",
      "Epoch: 25/100 Iteration: 243 Training loss: 0.09978\n",
      "Epoch: 25/100 Iteration: 244 Training loss: 0.05192\n",
      "Epoch: 24/100 Iteration: 245 Validation Acc: 0.7715\n",
      "Epoch: 25/100 Iteration: 245 Training loss: 0.05304\n",
      "Epoch: 25/100 Iteration: 246 Training loss: 0.10958\n",
      "Epoch: 25/100 Iteration: 247 Training loss: 0.11233\n",
      "Epoch: 25/100 Iteration: 248 Training loss: 0.09842\n",
      "Epoch: 25/100 Iteration: 249 Training loss: 0.05652\n",
      "Epoch: 24/100 Iteration: 250 Validation Acc: 0.7956\n",
      "Epoch: 26/100 Iteration: 250 Training loss: 0.05681\n",
      "Epoch: 26/100 Iteration: 251 Training loss: 0.05057\n",
      "Epoch: 26/100 Iteration: 252 Training loss: 0.05891\n",
      "Epoch: 26/100 Iteration: 253 Training loss: 0.08848\n",
      "Epoch: 26/100 Iteration: 254 Training loss: 0.05334\n",
      "Epoch: 25/100 Iteration: 255 Validation Acc: 0.8056\n",
      "Epoch: 26/100 Iteration: 255 Training loss: 0.04731\n",
      "Epoch: 26/100 Iteration: 256 Training loss: 0.05457\n",
      "Epoch: 26/100 Iteration: 257 Training loss: 0.06641\n",
      "Epoch: 26/100 Iteration: 258 Training loss: 0.04225\n",
      "Epoch: 26/100 Iteration: 259 Training loss: 0.03119\n",
      "Epoch: 25/100 Iteration: 260 Validation Acc: 0.7956\n",
      "Epoch: 27/100 Iteration: 260 Training loss: 0.02234\n",
      "Epoch: 27/100 Iteration: 261 Training loss: 0.01633\n",
      "Epoch: 27/100 Iteration: 262 Training loss: 0.02496\n",
      "Epoch: 27/100 Iteration: 263 Training loss: 0.03176\n",
      "Epoch: 27/100 Iteration: 264 Training loss: 0.03650\n",
      "Epoch: 26/100 Iteration: 265 Validation Acc: 0.7896\n",
      "Epoch: 27/100 Iteration: 265 Training loss: 0.03140\n",
      "Epoch: 27/100 Iteration: 266 Training loss: 0.02978\n",
      "Epoch: 27/100 Iteration: 267 Training loss: 0.02156\n",
      "Epoch: 27/100 Iteration: 268 Training loss: 0.01379\n",
      "Epoch: 27/100 Iteration: 269 Training loss: 0.01667\n",
      "Epoch: 26/100 Iteration: 270 Validation Acc: 0.8216\n",
      "Epoch: 28/100 Iteration: 270 Training loss: 0.01798\n",
      "Epoch: 28/100 Iteration: 271 Training loss: 0.01687\n",
      "Epoch: 28/100 Iteration: 272 Training loss: 0.02066\n",
      "Epoch: 28/100 Iteration: 273 Training loss: 0.01772\n",
      "Epoch: 28/100 Iteration: 274 Training loss: 0.01892\n",
      "Epoch: 27/100 Iteration: 275 Validation Acc: 0.8116\n",
      "Epoch: 28/100 Iteration: 275 Training loss: 0.01515\n",
      "Epoch: 28/100 Iteration: 276 Training loss: 0.01711\n",
      "Epoch: 28/100 Iteration: 277 Training loss: 0.01398\n",
      "Epoch: 28/100 Iteration: 278 Training loss: 0.01045\n",
      "Epoch: 28/100 Iteration: 279 Training loss: 0.01219\n",
      "Epoch: 27/100 Iteration: 280 Validation Acc: 0.8056\n",
      "Epoch: 29/100 Iteration: 280 Training loss: 0.01005\n",
      "Epoch: 29/100 Iteration: 281 Training loss: 0.00959\n",
      "Epoch: 29/100 Iteration: 282 Training loss: 0.01030\n",
      "Epoch: 29/100 Iteration: 283 Training loss: 0.01051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100 Iteration: 284 Training loss: 0.01312\n",
      "Epoch: 28/100 Iteration: 285 Validation Acc: 0.8016\n",
      "Epoch: 29/100 Iteration: 285 Training loss: 0.01189\n",
      "Epoch: 29/100 Iteration: 286 Training loss: 0.01557\n",
      "Epoch: 29/100 Iteration: 287 Training loss: 0.01221\n",
      "Epoch: 29/100 Iteration: 288 Training loss: 0.00912\n",
      "Epoch: 29/100 Iteration: 289 Training loss: 0.01038\n",
      "Epoch: 28/100 Iteration: 290 Validation Acc: 0.8156\n",
      "Epoch: 30/100 Iteration: 290 Training loss: 0.00865\n",
      "Epoch: 30/100 Iteration: 291 Training loss: 0.00749\n",
      "Epoch: 30/100 Iteration: 292 Training loss: 0.00868\n",
      "Epoch: 30/100 Iteration: 293 Training loss: 0.00840\n",
      "Epoch: 30/100 Iteration: 294 Training loss: 0.00929\n",
      "Epoch: 29/100 Iteration: 295 Validation Acc: 0.8216\n",
      "Epoch: 30/100 Iteration: 295 Training loss: 0.00891\n",
      "Epoch: 30/100 Iteration: 296 Training loss: 0.01146\n",
      "Epoch: 30/100 Iteration: 297 Training loss: 0.01070\n",
      "Epoch: 30/100 Iteration: 298 Training loss: 0.00709\n",
      "Epoch: 30/100 Iteration: 299 Training loss: 0.00910\n",
      "Epoch: 29/100 Iteration: 300 Validation Acc: 0.8196\n",
      "Epoch: 31/100 Iteration: 300 Training loss: 0.00793\n",
      "Epoch: 31/100 Iteration: 301 Training loss: 0.00631\n",
      "Epoch: 31/100 Iteration: 302 Training loss: 0.00747\n",
      "Epoch: 31/100 Iteration: 303 Training loss: 0.00748\n",
      "Epoch: 31/100 Iteration: 304 Training loss: 0.00825\n",
      "Epoch: 30/100 Iteration: 305 Validation Acc: 0.8216\n",
      "Epoch: 31/100 Iteration: 305 Training loss: 0.00782\n",
      "Epoch: 31/100 Iteration: 306 Training loss: 0.01062\n",
      "Epoch: 31/100 Iteration: 307 Training loss: 0.00848\n",
      "Epoch: 31/100 Iteration: 308 Training loss: 0.00705\n",
      "Epoch: 31/100 Iteration: 309 Training loss: 0.00824\n",
      "Epoch: 30/100 Iteration: 310 Validation Acc: 0.8176\n",
      "Epoch: 32/100 Iteration: 310 Training loss: 0.00712\n",
      "Epoch: 32/100 Iteration: 311 Training loss: 0.00594\n",
      "Epoch: 32/100 Iteration: 312 Training loss: 0.00633\n",
      "Epoch: 32/100 Iteration: 313 Training loss: 0.00644\n",
      "Epoch: 32/100 Iteration: 314 Training loss: 0.00725\n",
      "Epoch: 31/100 Iteration: 315 Validation Acc: 0.8176\n",
      "Epoch: 32/100 Iteration: 315 Training loss: 0.00684\n",
      "Epoch: 32/100 Iteration: 316 Training loss: 0.00882\n",
      "Epoch: 32/100 Iteration: 317 Training loss: 0.00788\n",
      "Epoch: 32/100 Iteration: 318 Training loss: 0.00608\n",
      "Epoch: 32/100 Iteration: 319 Training loss: 0.00757\n",
      "Epoch: 31/100 Iteration: 320 Validation Acc: 0.8196\n",
      "Epoch: 33/100 Iteration: 320 Training loss: 0.00668\n",
      "Epoch: 33/100 Iteration: 321 Training loss: 0.00539\n",
      "Epoch: 33/100 Iteration: 322 Training loss: 0.00627\n",
      "Epoch: 33/100 Iteration: 323 Training loss: 0.00646\n",
      "Epoch: 33/100 Iteration: 324 Training loss: 0.00673\n",
      "Epoch: 32/100 Iteration: 325 Validation Acc: 0.8196\n",
      "Epoch: 33/100 Iteration: 325 Training loss: 0.00648\n",
      "Epoch: 33/100 Iteration: 326 Training loss: 0.00822\n",
      "Epoch: 33/100 Iteration: 327 Training loss: 0.00690\n",
      "Epoch: 33/100 Iteration: 328 Training loss: 0.00571\n",
      "Epoch: 33/100 Iteration: 329 Training loss: 0.00690\n",
      "Epoch: 32/100 Iteration: 330 Validation Acc: 0.8176\n",
      "Epoch: 34/100 Iteration: 330 Training loss: 0.00600\n",
      "Epoch: 34/100 Iteration: 331 Training loss: 0.00512\n",
      "Epoch: 34/100 Iteration: 332 Training loss: 0.00556\n",
      "Epoch: 34/100 Iteration: 333 Training loss: 0.00586\n",
      "Epoch: 34/100 Iteration: 334 Training loss: 0.00636\n",
      "Epoch: 33/100 Iteration: 335 Validation Acc: 0.8156\n",
      "Epoch: 34/100 Iteration: 335 Training loss: 0.00604\n",
      "Epoch: 34/100 Iteration: 336 Training loss: 0.00779\n",
      "Epoch: 34/100 Iteration: 337 Training loss: 0.00659\n",
      "Epoch: 34/100 Iteration: 338 Training loss: 0.00547\n",
      "Epoch: 34/100 Iteration: 339 Training loss: 0.00654\n",
      "Epoch: 33/100 Iteration: 340 Validation Acc: 0.8156\n",
      "Epoch: 35/100 Iteration: 340 Training loss: 0.00564\n",
      "Epoch: 35/100 Iteration: 341 Training loss: 0.00477\n",
      "Epoch: 35/100 Iteration: 342 Training loss: 0.00534\n",
      "Epoch: 35/100 Iteration: 343 Training loss: 0.00560\n",
      "Epoch: 35/100 Iteration: 344 Training loss: 0.00597\n",
      "Epoch: 34/100 Iteration: 345 Validation Acc: 0.8156\n",
      "Epoch: 35/100 Iteration: 345 Training loss: 0.00574\n",
      "Epoch: 35/100 Iteration: 346 Training loss: 0.00714\n",
      "Epoch: 35/100 Iteration: 347 Training loss: 0.00615\n",
      "Epoch: 35/100 Iteration: 348 Training loss: 0.00518\n",
      "Epoch: 35/100 Iteration: 349 Training loss: 0.00615\n",
      "Epoch: 34/100 Iteration: 350 Validation Acc: 0.8156\n",
      "Epoch: 36/100 Iteration: 350 Training loss: 0.00530\n",
      "Epoch: 36/100 Iteration: 351 Training loss: 0.00455\n",
      "Epoch: 36/100 Iteration: 352 Training loss: 0.00498\n",
      "Epoch: 36/100 Iteration: 353 Training loss: 0.00533\n",
      "Epoch: 36/100 Iteration: 354 Training loss: 0.00570\n",
      "Epoch: 35/100 Iteration: 355 Validation Acc: 0.8156\n",
      "Epoch: 36/100 Iteration: 355 Training loss: 0.00544\n",
      "Epoch: 36/100 Iteration: 356 Training loss: 0.00681\n",
      "Epoch: 36/100 Iteration: 357 Training loss: 0.00582\n",
      "Epoch: 36/100 Iteration: 358 Training loss: 0.00497\n",
      "Epoch: 36/100 Iteration: 359 Training loss: 0.00584\n",
      "Epoch: 35/100 Iteration: 360 Validation Acc: 0.8156\n",
      "Epoch: 37/100 Iteration: 360 Training loss: 0.00500\n",
      "Epoch: 37/100 Iteration: 361 Training loss: 0.00432\n",
      "Epoch: 37/100 Iteration: 362 Training loss: 0.00470\n",
      "Epoch: 37/100 Iteration: 363 Training loss: 0.00505\n",
      "Epoch: 37/100 Iteration: 364 Training loss: 0.00542\n",
      "Epoch: 36/100 Iteration: 365 Validation Acc: 0.8176\n",
      "Epoch: 37/100 Iteration: 365 Training loss: 0.00513\n",
      "Epoch: 37/100 Iteration: 366 Training loss: 0.00640\n",
      "Epoch: 37/100 Iteration: 367 Training loss: 0.00555\n",
      "Epoch: 37/100 Iteration: 368 Training loss: 0.00476\n",
      "Epoch: 37/100 Iteration: 369 Training loss: 0.00557\n",
      "Epoch: 36/100 Iteration: 370 Validation Acc: 0.8156\n",
      "Epoch: 38/100 Iteration: 370 Training loss: 0.00475\n",
      "Epoch: 38/100 Iteration: 371 Training loss: 0.00413\n",
      "Epoch: 38/100 Iteration: 372 Training loss: 0.00448\n",
      "Epoch: 38/100 Iteration: 373 Training loss: 0.00487\n",
      "Epoch: 38/100 Iteration: 374 Training loss: 0.00518\n",
      "Epoch: 37/100 Iteration: 375 Validation Acc: 0.8176\n",
      "Epoch: 38/100 Iteration: 375 Training loss: 0.00489\n",
      "Epoch: 38/100 Iteration: 376 Training loss: 0.00604\n",
      "Epoch: 38/100 Iteration: 377 Training loss: 0.00527\n",
      "Epoch: 38/100 Iteration: 378 Training loss: 0.00455\n",
      "Epoch: 38/100 Iteration: 379 Training loss: 0.00529\n",
      "Epoch: 37/100 Iteration: 380 Validation Acc: 0.8156\n",
      "Epoch: 39/100 Iteration: 380 Training loss: 0.00451\n",
      "Epoch: 39/100 Iteration: 381 Training loss: 0.00395\n",
      "Epoch: 39/100 Iteration: 382 Training loss: 0.00425\n",
      "Epoch: 39/100 Iteration: 383 Training loss: 0.00465\n",
      "Epoch: 39/100 Iteration: 384 Training loss: 0.00496\n",
      "Epoch: 38/100 Iteration: 385 Validation Acc: 0.8176\n",
      "Epoch: 39/100 Iteration: 385 Training loss: 0.00466\n",
      "Epoch: 39/100 Iteration: 386 Training loss: 0.00575\n",
      "Epoch: 39/100 Iteration: 387 Training loss: 0.00505\n",
      "Epoch: 39/100 Iteration: 388 Training loss: 0.00438\n",
      "Epoch: 39/100 Iteration: 389 Training loss: 0.00505\n",
      "Epoch: 38/100 Iteration: 390 Validation Acc: 0.8156\n",
      "Epoch: 40/100 Iteration: 390 Training loss: 0.00430\n",
      "Epoch: 40/100 Iteration: 391 Training loss: 0.00379\n",
      "Epoch: 40/100 Iteration: 392 Training loss: 0.00407\n",
      "Epoch: 40/100 Iteration: 393 Training loss: 0.00447\n",
      "Epoch: 40/100 Iteration: 394 Training loss: 0.00476\n",
      "Epoch: 39/100 Iteration: 395 Validation Acc: 0.8176\n",
      "Epoch: 40/100 Iteration: 395 Training loss: 0.00446\n",
      "Epoch: 40/100 Iteration: 396 Training loss: 0.00547\n",
      "Epoch: 40/100 Iteration: 397 Training loss: 0.00483\n",
      "Epoch: 40/100 Iteration: 398 Training loss: 0.00421\n",
      "Epoch: 40/100 Iteration: 399 Training loss: 0.00484\n",
      "Epoch: 39/100 Iteration: 400 Validation Acc: 0.8156\n",
      "Epoch: 41/100 Iteration: 400 Training loss: 0.00410\n",
      "Epoch: 41/100 Iteration: 401 Training loss: 0.00364\n",
      "Epoch: 41/100 Iteration: 402 Training loss: 0.00390\n",
      "Epoch: 41/100 Iteration: 403 Training loss: 0.00429\n",
      "Epoch: 41/100 Iteration: 404 Training loss: 0.00458\n",
      "Epoch: 40/100 Iteration: 405 Validation Acc: 0.8176\n",
      "Epoch: 41/100 Iteration: 405 Training loss: 0.00427\n",
      "Epoch: 41/100 Iteration: 406 Training loss: 0.00523\n",
      "Epoch: 41/100 Iteration: 407 Training loss: 0.00464\n",
      "Epoch: 41/100 Iteration: 408 Training loss: 0.00406\n",
      "Epoch: 41/100 Iteration: 409 Training loss: 0.00463\n",
      "Epoch: 40/100 Iteration: 410 Validation Acc: 0.8156\n",
      "Epoch: 42/100 Iteration: 410 Training loss: 0.00393\n",
      "Epoch: 42/100 Iteration: 411 Training loss: 0.00350\n",
      "Epoch: 42/100 Iteration: 412 Training loss: 0.00376\n",
      "Epoch: 42/100 Iteration: 413 Training loss: 0.00413\n",
      "Epoch: 42/100 Iteration: 414 Training loss: 0.00440\n",
      "Epoch: 41/100 Iteration: 415 Validation Acc: 0.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100 Iteration: 415 Training loss: 0.00410\n",
      "Epoch: 42/100 Iteration: 416 Training loss: 0.00500\n",
      "Epoch: 42/100 Iteration: 417 Training loss: 0.00445\n",
      "Epoch: 42/100 Iteration: 418 Training loss: 0.00391\n",
      "Epoch: 42/100 Iteration: 419 Training loss: 0.00445\n",
      "Epoch: 41/100 Iteration: 420 Validation Acc: 0.8156\n",
      "Epoch: 43/100 Iteration: 420 Training loss: 0.00377\n",
      "Epoch: 43/100 Iteration: 421 Training loss: 0.00337\n",
      "Epoch: 43/100 Iteration: 422 Training loss: 0.00361\n",
      "Epoch: 43/100 Iteration: 423 Training loss: 0.00397\n",
      "Epoch: 43/100 Iteration: 424 Training loss: 0.00423\n",
      "Epoch: 42/100 Iteration: 425 Validation Acc: 0.8156\n",
      "Epoch: 43/100 Iteration: 425 Training loss: 0.00395\n",
      "Epoch: 43/100 Iteration: 426 Training loss: 0.00481\n",
      "Epoch: 43/100 Iteration: 427 Training loss: 0.00430\n",
      "Epoch: 43/100 Iteration: 428 Training loss: 0.00378\n",
      "Epoch: 43/100 Iteration: 429 Training loss: 0.00428\n",
      "Epoch: 42/100 Iteration: 430 Validation Acc: 0.8156\n",
      "Epoch: 44/100 Iteration: 430 Training loss: 0.00362\n",
      "Epoch: 44/100 Iteration: 431 Training loss: 0.00326\n",
      "Epoch: 44/100 Iteration: 432 Training loss: 0.00349\n",
      "Epoch: 44/100 Iteration: 433 Training loss: 0.00383\n",
      "Epoch: 44/100 Iteration: 434 Training loss: 0.00409\n",
      "Epoch: 43/100 Iteration: 435 Validation Acc: 0.8156\n",
      "Epoch: 44/100 Iteration: 435 Training loss: 0.00380\n",
      "Epoch: 44/100 Iteration: 436 Training loss: 0.00462\n",
      "Epoch: 44/100 Iteration: 437 Training loss: 0.00413\n",
      "Epoch: 44/100 Iteration: 438 Training loss: 0.00365\n",
      "Epoch: 44/100 Iteration: 439 Training loss: 0.00413\n",
      "Epoch: 43/100 Iteration: 440 Validation Acc: 0.8176\n",
      "Epoch: 45/100 Iteration: 440 Training loss: 0.00349\n",
      "Epoch: 45/100 Iteration: 441 Training loss: 0.00314\n",
      "Epoch: 45/100 Iteration: 442 Training loss: 0.00336\n",
      "Epoch: 45/100 Iteration: 443 Training loss: 0.00370\n",
      "Epoch: 45/100 Iteration: 444 Training loss: 0.00395\n",
      "Epoch: 44/100 Iteration: 445 Validation Acc: 0.8156\n",
      "Epoch: 45/100 Iteration: 445 Training loss: 0.00368\n",
      "Epoch: 45/100 Iteration: 446 Training loss: 0.00444\n",
      "Epoch: 45/100 Iteration: 447 Training loss: 0.00399\n",
      "Epoch: 45/100 Iteration: 448 Training loss: 0.00353\n",
      "Epoch: 45/100 Iteration: 449 Training loss: 0.00397\n",
      "Epoch: 44/100 Iteration: 450 Validation Acc: 0.8176\n",
      "Epoch: 46/100 Iteration: 450 Training loss: 0.00337\n",
      "Epoch: 46/100 Iteration: 451 Training loss: 0.00304\n",
      "Epoch: 46/100 Iteration: 452 Training loss: 0.00325\n",
      "Epoch: 46/100 Iteration: 453 Training loss: 0.00359\n",
      "Epoch: 46/100 Iteration: 454 Training loss: 0.00381\n",
      "Epoch: 45/100 Iteration: 455 Validation Acc: 0.8156\n",
      "Epoch: 46/100 Iteration: 455 Training loss: 0.00356\n",
      "Epoch: 46/100 Iteration: 456 Training loss: 0.00427\n",
      "Epoch: 46/100 Iteration: 457 Training loss: 0.00384\n",
      "Epoch: 46/100 Iteration: 458 Training loss: 0.00342\n",
      "Epoch: 46/100 Iteration: 459 Training loss: 0.00384\n",
      "Epoch: 45/100 Iteration: 460 Validation Acc: 0.8176\n",
      "Epoch: 47/100 Iteration: 460 Training loss: 0.00325\n",
      "Epoch: 47/100 Iteration: 461 Training loss: 0.00295\n",
      "Epoch: 47/100 Iteration: 462 Training loss: 0.00315\n",
      "Epoch: 47/100 Iteration: 463 Training loss: 0.00347\n",
      "Epoch: 47/100 Iteration: 464 Training loss: 0.00369\n",
      "Epoch: 46/100 Iteration: 465 Validation Acc: 0.8176\n",
      "Epoch: 47/100 Iteration: 465 Training loss: 0.00344\n",
      "Epoch: 47/100 Iteration: 466 Training loss: 0.00413\n",
      "Epoch: 47/100 Iteration: 467 Training loss: 0.00372\n",
      "Epoch: 47/100 Iteration: 468 Training loss: 0.00332\n",
      "Epoch: 47/100 Iteration: 469 Training loss: 0.00371\n",
      "Epoch: 46/100 Iteration: 470 Validation Acc: 0.8176\n",
      "Epoch: 48/100 Iteration: 470 Training loss: 0.00314\n",
      "Epoch: 48/100 Iteration: 471 Training loss: 0.00286\n",
      "Epoch: 48/100 Iteration: 472 Training loss: 0.00305\n",
      "Epoch: 48/100 Iteration: 473 Training loss: 0.00337\n",
      "Epoch: 48/100 Iteration: 474 Training loss: 0.00357\n",
      "Epoch: 47/100 Iteration: 475 Validation Acc: 0.8176\n",
      "Epoch: 48/100 Iteration: 475 Training loss: 0.00333\n",
      "Epoch: 48/100 Iteration: 476 Training loss: 0.00399\n",
      "Epoch: 48/100 Iteration: 477 Training loss: 0.00360\n",
      "Epoch: 48/100 Iteration: 478 Training loss: 0.00323\n",
      "Epoch: 48/100 Iteration: 479 Training loss: 0.00359\n",
      "Epoch: 47/100 Iteration: 480 Validation Acc: 0.8156\n",
      "Epoch: 49/100 Iteration: 480 Training loss: 0.00304\n",
      "Epoch: 49/100 Iteration: 481 Training loss: 0.00278\n",
      "Epoch: 49/100 Iteration: 482 Training loss: 0.00296\n",
      "Epoch: 49/100 Iteration: 483 Training loss: 0.00327\n",
      "Epoch: 49/100 Iteration: 484 Training loss: 0.00346\n",
      "Epoch: 48/100 Iteration: 485 Validation Acc: 0.8156\n",
      "Epoch: 49/100 Iteration: 485 Training loss: 0.00323\n",
      "Epoch: 49/100 Iteration: 486 Training loss: 0.00386\n",
      "Epoch: 49/100 Iteration: 487 Training loss: 0.00349\n",
      "Epoch: 49/100 Iteration: 488 Training loss: 0.00313\n",
      "Epoch: 49/100 Iteration: 489 Training loss: 0.00348\n",
      "Epoch: 48/100 Iteration: 490 Validation Acc: 0.8156\n",
      "Epoch: 50/100 Iteration: 490 Training loss: 0.00295\n",
      "Epoch: 50/100 Iteration: 491 Training loss: 0.00270\n",
      "Epoch: 50/100 Iteration: 492 Training loss: 0.00287\n",
      "Epoch: 50/100 Iteration: 493 Training loss: 0.00317\n",
      "Epoch: 50/100 Iteration: 494 Training loss: 0.00336\n",
      "Epoch: 49/100 Iteration: 495 Validation Acc: 0.8136\n",
      "Epoch: 50/100 Iteration: 495 Training loss: 0.00314\n",
      "Epoch: 50/100 Iteration: 496 Training loss: 0.00374\n",
      "Epoch: 50/100 Iteration: 497 Training loss: 0.00338\n",
      "Epoch: 50/100 Iteration: 498 Training loss: 0.00304\n",
      "Epoch: 50/100 Iteration: 499 Training loss: 0.00337\n",
      "Epoch: 49/100 Iteration: 500 Validation Acc: 0.8156\n",
      "Epoch: 51/100 Iteration: 500 Training loss: 0.00286\n",
      "Epoch: 51/100 Iteration: 501 Training loss: 0.00263\n",
      "Epoch: 51/100 Iteration: 502 Training loss: 0.00279\n",
      "Epoch: 51/100 Iteration: 503 Training loss: 0.00308\n",
      "Epoch: 51/100 Iteration: 504 Training loss: 0.00326\n",
      "Epoch: 50/100 Iteration: 505 Validation Acc: 0.8156\n",
      "Epoch: 51/100 Iteration: 505 Training loss: 0.00305\n",
      "Epoch: 51/100 Iteration: 506 Training loss: 0.00363\n",
      "Epoch: 51/100 Iteration: 507 Training loss: 0.00328\n",
      "Epoch: 51/100 Iteration: 508 Training loss: 0.00296\n",
      "Epoch: 51/100 Iteration: 509 Training loss: 0.00327\n",
      "Epoch: 50/100 Iteration: 510 Validation Acc: 0.8156\n",
      "Epoch: 52/100 Iteration: 510 Training loss: 0.00277\n",
      "Epoch: 52/100 Iteration: 511 Training loss: 0.00255\n",
      "Epoch: 52/100 Iteration: 512 Training loss: 0.00271\n",
      "Epoch: 52/100 Iteration: 513 Training loss: 0.00300\n",
      "Epoch: 52/100 Iteration: 514 Training loss: 0.00317\n",
      "Epoch: 51/100 Iteration: 515 Validation Acc: 0.8136\n",
      "Epoch: 52/100 Iteration: 515 Training loss: 0.00297\n",
      "Epoch: 52/100 Iteration: 516 Training loss: 0.00352\n",
      "Epoch: 52/100 Iteration: 517 Training loss: 0.00318\n",
      "Epoch: 52/100 Iteration: 518 Training loss: 0.00288\n",
      "Epoch: 52/100 Iteration: 519 Training loss: 0.00317\n",
      "Epoch: 51/100 Iteration: 520 Validation Acc: 0.8176\n",
      "Epoch: 53/100 Iteration: 520 Training loss: 0.00269\n",
      "Epoch: 53/100 Iteration: 521 Training loss: 0.00248\n",
      "Epoch: 53/100 Iteration: 522 Training loss: 0.00263\n",
      "Epoch: 53/100 Iteration: 523 Training loss: 0.00291\n",
      "Epoch: 53/100 Iteration: 524 Training loss: 0.00307\n",
      "Epoch: 52/100 Iteration: 525 Validation Acc: 0.8156\n",
      "Epoch: 53/100 Iteration: 525 Training loss: 0.00288\n",
      "Epoch: 53/100 Iteration: 526 Training loss: 0.00342\n",
      "Epoch: 53/100 Iteration: 527 Training loss: 0.00309\n",
      "Epoch: 53/100 Iteration: 528 Training loss: 0.00280\n",
      "Epoch: 53/100 Iteration: 529 Training loss: 0.00307\n",
      "Epoch: 52/100 Iteration: 530 Validation Acc: 0.8176\n",
      "Epoch: 54/100 Iteration: 530 Training loss: 0.00262\n",
      "Epoch: 54/100 Iteration: 531 Training loss: 0.00242\n",
      "Epoch: 54/100 Iteration: 532 Training loss: 0.00256\n",
      "Epoch: 54/100 Iteration: 533 Training loss: 0.00283\n",
      "Epoch: 54/100 Iteration: 534 Training loss: 0.00299\n",
      "Epoch: 53/100 Iteration: 535 Validation Acc: 0.8156\n",
      "Epoch: 54/100 Iteration: 535 Training loss: 0.00281\n",
      "Epoch: 54/100 Iteration: 536 Training loss: 0.00332\n",
      "Epoch: 54/100 Iteration: 537 Training loss: 0.00300\n",
      "Epoch: 54/100 Iteration: 538 Training loss: 0.00273\n",
      "Epoch: 54/100 Iteration: 539 Training loss: 0.00299\n",
      "Epoch: 53/100 Iteration: 540 Validation Acc: 0.8176\n",
      "Epoch: 55/100 Iteration: 540 Training loss: 0.00254\n",
      "Epoch: 55/100 Iteration: 541 Training loss: 0.00236\n",
      "Epoch: 55/100 Iteration: 542 Training loss: 0.00249\n",
      "Epoch: 55/100 Iteration: 543 Training loss: 0.00276\n",
      "Epoch: 55/100 Iteration: 544 Training loss: 0.00291\n",
      "Epoch: 54/100 Iteration: 545 Validation Acc: 0.8176\n",
      "Epoch: 55/100 Iteration: 545 Training loss: 0.00273\n",
      "Epoch: 55/100 Iteration: 546 Training loss: 0.00323\n",
      "Epoch: 55/100 Iteration: 547 Training loss: 0.00292\n",
      "Epoch: 55/100 Iteration: 548 Training loss: 0.00266\n",
      "Epoch: 55/100 Iteration: 549 Training loss: 0.00290\n",
      "Epoch: 54/100 Iteration: 550 Validation Acc: 0.8176\n",
      "Epoch: 56/100 Iteration: 550 Training loss: 0.00247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100 Iteration: 551 Training loss: 0.00230\n",
      "Epoch: 56/100 Iteration: 552 Training loss: 0.00242\n",
      "Epoch: 56/100 Iteration: 553 Training loss: 0.00269\n",
      "Epoch: 56/100 Iteration: 554 Training loss: 0.00283\n",
      "Epoch: 55/100 Iteration: 555 Validation Acc: 0.8176\n",
      "Epoch: 56/100 Iteration: 555 Training loss: 0.00266\n",
      "Epoch: 56/100 Iteration: 556 Training loss: 0.00314\n",
      "Epoch: 56/100 Iteration: 557 Training loss: 0.00284\n",
      "Epoch: 56/100 Iteration: 558 Training loss: 0.00259\n",
      "Epoch: 56/100 Iteration: 559 Training loss: 0.00282\n",
      "Epoch: 55/100 Iteration: 560 Validation Acc: 0.8136\n",
      "Epoch: 57/100 Iteration: 560 Training loss: 0.00241\n",
      "Epoch: 57/100 Iteration: 561 Training loss: 0.00224\n",
      "Epoch: 57/100 Iteration: 562 Training loss: 0.00236\n",
      "Epoch: 57/100 Iteration: 563 Training loss: 0.00261\n",
      "Epoch: 57/100 Iteration: 564 Training loss: 0.00276\n",
      "Epoch: 56/100 Iteration: 565 Validation Acc: 0.8156\n",
      "Epoch: 57/100 Iteration: 565 Training loss: 0.00259\n",
      "Epoch: 57/100 Iteration: 566 Training loss: 0.00305\n",
      "Epoch: 57/100 Iteration: 567 Training loss: 0.00276\n",
      "Epoch: 57/100 Iteration: 568 Training loss: 0.00253\n",
      "Epoch: 57/100 Iteration: 569 Training loss: 0.00274\n",
      "Epoch: 56/100 Iteration: 570 Validation Acc: 0.8136\n",
      "Epoch: 58/100 Iteration: 570 Training loss: 0.00234\n",
      "Epoch: 58/100 Iteration: 571 Training loss: 0.00218\n",
      "Epoch: 58/100 Iteration: 572 Training loss: 0.00230\n",
      "Epoch: 58/100 Iteration: 573 Training loss: 0.00255\n",
      "Epoch: 58/100 Iteration: 574 Training loss: 0.00269\n",
      "Epoch: 57/100 Iteration: 575 Validation Acc: 0.8156\n",
      "Epoch: 58/100 Iteration: 575 Training loss: 0.00253\n",
      "Epoch: 58/100 Iteration: 576 Training loss: 0.00297\n",
      "Epoch: 58/100 Iteration: 577 Training loss: 0.00269\n",
      "Epoch: 58/100 Iteration: 578 Training loss: 0.00247\n",
      "Epoch: 58/100 Iteration: 579 Training loss: 0.00268\n",
      "Epoch: 57/100 Iteration: 580 Validation Acc: 0.8156\n",
      "Epoch: 59/100 Iteration: 580 Training loss: 0.00228\n",
      "Epoch: 59/100 Iteration: 581 Training loss: 0.00213\n",
      "Epoch: 59/100 Iteration: 582 Training loss: 0.00224\n",
      "Epoch: 59/100 Iteration: 583 Training loss: 0.00248\n",
      "Epoch: 59/100 Iteration: 584 Training loss: 0.00262\n",
      "Epoch: 58/100 Iteration: 585 Validation Acc: 0.8156\n",
      "Epoch: 59/100 Iteration: 585 Training loss: 0.00246\n",
      "Epoch: 59/100 Iteration: 586 Training loss: 0.00289\n",
      "Epoch: 59/100 Iteration: 587 Training loss: 0.00262\n",
      "Epoch: 59/100 Iteration: 588 Training loss: 0.00241\n",
      "Epoch: 59/100 Iteration: 589 Training loss: 0.00260\n",
      "Epoch: 58/100 Iteration: 590 Validation Acc: 0.8136\n",
      "Epoch: 60/100 Iteration: 590 Training loss: 0.00222\n",
      "Epoch: 60/100 Iteration: 591 Training loss: 0.00208\n",
      "Epoch: 60/100 Iteration: 592 Training loss: 0.00218\n",
      "Epoch: 60/100 Iteration: 593 Training loss: 0.00242\n",
      "Epoch: 60/100 Iteration: 594 Training loss: 0.00255\n",
      "Epoch: 59/100 Iteration: 595 Validation Acc: 0.8156\n",
      "Epoch: 60/100 Iteration: 595 Training loss: 0.00240\n",
      "Epoch: 60/100 Iteration: 596 Training loss: 0.00282\n",
      "Epoch: 60/100 Iteration: 597 Training loss: 0.00255\n",
      "Epoch: 60/100 Iteration: 598 Training loss: 0.00235\n",
      "Epoch: 60/100 Iteration: 599 Training loss: 0.00254\n",
      "Epoch: 59/100 Iteration: 600 Validation Acc: 0.8136\n",
      "Epoch: 61/100 Iteration: 600 Training loss: 0.00216\n",
      "Epoch: 61/100 Iteration: 601 Training loss: 0.00203\n",
      "Epoch: 61/100 Iteration: 602 Training loss: 0.00213\n",
      "Epoch: 61/100 Iteration: 603 Training loss: 0.00236\n",
      "Epoch: 61/100 Iteration: 604 Training loss: 0.00249\n",
      "Epoch: 60/100 Iteration: 605 Validation Acc: 0.8156\n",
      "Epoch: 61/100 Iteration: 605 Training loss: 0.00234\n",
      "Epoch: 61/100 Iteration: 606 Training loss: 0.00275\n",
      "Epoch: 61/100 Iteration: 607 Training loss: 0.00249\n",
      "Epoch: 61/100 Iteration: 608 Training loss: 0.00230\n",
      "Epoch: 61/100 Iteration: 609 Training loss: 0.00248\n",
      "Epoch: 60/100 Iteration: 610 Validation Acc: 0.8136\n",
      "Epoch: 62/100 Iteration: 610 Training loss: 0.00211\n",
      "Epoch: 62/100 Iteration: 611 Training loss: 0.00198\n",
      "Epoch: 62/100 Iteration: 612 Training loss: 0.00207\n",
      "Epoch: 62/100 Iteration: 613 Training loss: 0.00230\n",
      "Epoch: 62/100 Iteration: 614 Training loss: 0.00243\n",
      "Epoch: 61/100 Iteration: 615 Validation Acc: 0.8176\n",
      "Epoch: 62/100 Iteration: 615 Training loss: 0.00229\n",
      "Epoch: 62/100 Iteration: 616 Training loss: 0.00268\n",
      "Epoch: 62/100 Iteration: 617 Training loss: 0.00243\n",
      "Epoch: 62/100 Iteration: 618 Training loss: 0.00225\n",
      "Epoch: 62/100 Iteration: 619 Training loss: 0.00241\n",
      "Epoch: 61/100 Iteration: 620 Validation Acc: 0.8136\n",
      "Epoch: 63/100 Iteration: 620 Training loss: 0.00206\n",
      "Epoch: 63/100 Iteration: 621 Training loss: 0.00194\n",
      "Epoch: 63/100 Iteration: 622 Training loss: 0.00202\n",
      "Epoch: 63/100 Iteration: 623 Training loss: 0.00225\n",
      "Epoch: 63/100 Iteration: 624 Training loss: 0.00237\n",
      "Epoch: 62/100 Iteration: 625 Validation Acc: 0.8176\n",
      "Epoch: 63/100 Iteration: 625 Training loss: 0.00223\n",
      "Epoch: 63/100 Iteration: 626 Training loss: 0.00261\n",
      "Epoch: 63/100 Iteration: 627 Training loss: 0.00237\n",
      "Epoch: 63/100 Iteration: 628 Training loss: 0.00220\n",
      "Epoch: 63/100 Iteration: 629 Training loss: 0.00236\n",
      "Epoch: 62/100 Iteration: 630 Validation Acc: 0.8136\n",
      "Epoch: 64/100 Iteration: 630 Training loss: 0.00201\n",
      "Epoch: 64/100 Iteration: 631 Training loss: 0.00189\n",
      "Epoch: 64/100 Iteration: 632 Training loss: 0.00198\n",
      "Epoch: 64/100 Iteration: 633 Training loss: 0.00220\n",
      "Epoch: 64/100 Iteration: 634 Training loss: 0.00231\n",
      "Epoch: 63/100 Iteration: 635 Validation Acc: 0.8196\n",
      "Epoch: 64/100 Iteration: 635 Training loss: 0.00218\n",
      "Epoch: 64/100 Iteration: 636 Training loss: 0.00255\n",
      "Epoch: 64/100 Iteration: 637 Training loss: 0.00231\n",
      "Epoch: 64/100 Iteration: 638 Training loss: 0.00215\n",
      "Epoch: 64/100 Iteration: 639 Training loss: 0.00230\n",
      "Epoch: 63/100 Iteration: 640 Validation Acc: 0.8156\n",
      "Epoch: 65/100 Iteration: 640 Training loss: 0.00196\n",
      "Epoch: 65/100 Iteration: 641 Training loss: 0.00185\n",
      "Epoch: 65/100 Iteration: 642 Training loss: 0.00193\n",
      "Epoch: 65/100 Iteration: 643 Training loss: 0.00214\n",
      "Epoch: 65/100 Iteration: 644 Training loss: 0.00225\n",
      "Epoch: 64/100 Iteration: 645 Validation Acc: 0.8196\n",
      "Epoch: 65/100 Iteration: 645 Training loss: 0.00213\n",
      "Epoch: 65/100 Iteration: 646 Training loss: 0.00249\n",
      "Epoch: 65/100 Iteration: 647 Training loss: 0.00226\n",
      "Epoch: 65/100 Iteration: 648 Training loss: 0.00210\n",
      "Epoch: 65/100 Iteration: 649 Training loss: 0.00225\n",
      "Epoch: 64/100 Iteration: 650 Validation Acc: 0.8176\n",
      "Epoch: 66/100 Iteration: 650 Training loss: 0.00192\n",
      "Epoch: 66/100 Iteration: 651 Training loss: 0.00181\n",
      "Epoch: 66/100 Iteration: 652 Training loss: 0.00188\n",
      "Epoch: 66/100 Iteration: 653 Training loss: 0.00210\n",
      "Epoch: 66/100 Iteration: 654 Training loss: 0.00220\n",
      "Epoch: 65/100 Iteration: 655 Validation Acc: 0.8176\n",
      "Epoch: 66/100 Iteration: 655 Training loss: 0.00208\n",
      "Epoch: 66/100 Iteration: 656 Training loss: 0.00243\n",
      "Epoch: 66/100 Iteration: 657 Training loss: 0.00220\n",
      "Epoch: 66/100 Iteration: 658 Training loss: 0.00205\n",
      "Epoch: 66/100 Iteration: 659 Training loss: 0.00219\n",
      "Epoch: 65/100 Iteration: 660 Validation Acc: 0.8156\n",
      "Epoch: 67/100 Iteration: 660 Training loss: 0.00187\n",
      "Epoch: 67/100 Iteration: 661 Training loss: 0.00177\n",
      "Epoch: 67/100 Iteration: 662 Training loss: 0.00184\n",
      "Epoch: 67/100 Iteration: 663 Training loss: 0.00205\n",
      "Epoch: 67/100 Iteration: 664 Training loss: 0.00215\n",
      "Epoch: 66/100 Iteration: 665 Validation Acc: 0.8196\n",
      "Epoch: 67/100 Iteration: 665 Training loss: 0.00203\n",
      "Epoch: 67/100 Iteration: 666 Training loss: 0.00238\n",
      "Epoch: 67/100 Iteration: 667 Training loss: 0.00215\n",
      "Epoch: 67/100 Iteration: 668 Training loss: 0.00201\n",
      "Epoch: 67/100 Iteration: 669 Training loss: 0.00214\n",
      "Epoch: 66/100 Iteration: 670 Validation Acc: 0.8156\n",
      "Epoch: 68/100 Iteration: 670 Training loss: 0.00183\n",
      "Epoch: 68/100 Iteration: 671 Training loss: 0.00173\n",
      "Epoch: 68/100 Iteration: 672 Training loss: 0.00180\n",
      "Epoch: 68/100 Iteration: 673 Training loss: 0.00200\n",
      "Epoch: 68/100 Iteration: 674 Training loss: 0.00210\n",
      "Epoch: 67/100 Iteration: 675 Validation Acc: 0.8156\n",
      "Epoch: 68/100 Iteration: 675 Training loss: 0.00199\n",
      "Epoch: 68/100 Iteration: 676 Training loss: 0.00232\n",
      "Epoch: 68/100 Iteration: 677 Training loss: 0.00211\n",
      "Epoch: 68/100 Iteration: 678 Training loss: 0.00197\n",
      "Epoch: 68/100 Iteration: 679 Training loss: 0.00210\n",
      "Epoch: 67/100 Iteration: 680 Validation Acc: 0.8156\n",
      "Epoch: 69/100 Iteration: 680 Training loss: 0.00179\n",
      "Epoch: 69/100 Iteration: 681 Training loss: 0.00169\n",
      "Epoch: 69/100 Iteration: 682 Training loss: 0.00176\n",
      "Epoch: 69/100 Iteration: 683 Training loss: 0.00196\n",
      "Epoch: 69/100 Iteration: 684 Training loss: 0.00205\n",
      "Epoch: 68/100 Iteration: 685 Validation Acc: 0.8136\n",
      "Epoch: 69/100 Iteration: 685 Training loss: 0.00194\n",
      "Epoch: 69/100 Iteration: 686 Training loss: 0.00227\n",
      "Epoch: 69/100 Iteration: 687 Training loss: 0.00205\n",
      "Epoch: 69/100 Iteration: 688 Training loss: 0.00192\n",
      "Epoch: 69/100 Iteration: 689 Training loss: 0.00205\n",
      "Epoch: 68/100 Iteration: 690 Validation Acc: 0.8136\n",
      "Epoch: 70/100 Iteration: 690 Training loss: 0.00175\n",
      "Epoch: 70/100 Iteration: 691 Training loss: 0.00165\n",
      "Epoch: 70/100 Iteration: 692 Training loss: 0.00172\n",
      "Epoch: 70/100 Iteration: 693 Training loss: 0.00191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100 Iteration: 694 Training loss: 0.00201\n",
      "Epoch: 69/100 Iteration: 695 Validation Acc: 0.8136\n",
      "Epoch: 70/100 Iteration: 695 Training loss: 0.00190\n",
      "Epoch: 70/100 Iteration: 696 Training loss: 0.00222\n",
      "Epoch: 70/100 Iteration: 697 Training loss: 0.00201\n",
      "Epoch: 70/100 Iteration: 698 Training loss: 0.00188\n",
      "Epoch: 70/100 Iteration: 699 Training loss: 0.00200\n",
      "Epoch: 69/100 Iteration: 700 Validation Acc: 0.8156\n",
      "Epoch: 71/100 Iteration: 700 Training loss: 0.00171\n",
      "Epoch: 71/100 Iteration: 701 Training loss: 0.00162\n",
      "Epoch: 71/100 Iteration: 702 Training loss: 0.00168\n",
      "Epoch: 71/100 Iteration: 703 Training loss: 0.00187\n",
      "Epoch: 71/100 Iteration: 704 Training loss: 0.00196\n",
      "Epoch: 70/100 Iteration: 705 Validation Acc: 0.8136\n",
      "Epoch: 71/100 Iteration: 705 Training loss: 0.00186\n",
      "Epoch: 71/100 Iteration: 706 Training loss: 0.00217\n",
      "Epoch: 71/100 Iteration: 707 Training loss: 0.00196\n",
      "Epoch: 71/100 Iteration: 708 Training loss: 0.00184\n",
      "Epoch: 71/100 Iteration: 709 Training loss: 0.00196\n",
      "Epoch: 70/100 Iteration: 710 Validation Acc: 0.8136\n",
      "Epoch: 72/100 Iteration: 710 Training loss: 0.00167\n",
      "Epoch: 72/100 Iteration: 711 Training loss: 0.00159\n",
      "Epoch: 72/100 Iteration: 712 Training loss: 0.00164\n",
      "Epoch: 72/100 Iteration: 713 Training loss: 0.00183\n",
      "Epoch: 72/100 Iteration: 714 Training loss: 0.00192\n",
      "Epoch: 71/100 Iteration: 715 Validation Acc: 0.8136\n",
      "Epoch: 72/100 Iteration: 715 Training loss: 0.00182\n",
      "Epoch: 72/100 Iteration: 716 Training loss: 0.00212\n",
      "Epoch: 72/100 Iteration: 717 Training loss: 0.00192\n",
      "Epoch: 72/100 Iteration: 718 Training loss: 0.00181\n",
      "Epoch: 72/100 Iteration: 719 Training loss: 0.00192\n",
      "Epoch: 71/100 Iteration: 720 Validation Acc: 0.8136\n",
      "Epoch: 73/100 Iteration: 720 Training loss: 0.00164\n",
      "Epoch: 73/100 Iteration: 721 Training loss: 0.00155\n",
      "Epoch: 73/100 Iteration: 722 Training loss: 0.00161\n",
      "Epoch: 73/100 Iteration: 723 Training loss: 0.00179\n",
      "Epoch: 73/100 Iteration: 724 Training loss: 0.00188\n",
      "Epoch: 72/100 Iteration: 725 Validation Acc: 0.8136\n",
      "Epoch: 73/100 Iteration: 725 Training loss: 0.00178\n",
      "Epoch: 73/100 Iteration: 726 Training loss: 0.00207\n",
      "Epoch: 73/100 Iteration: 727 Training loss: 0.00188\n",
      "Epoch: 73/100 Iteration: 728 Training loss: 0.00177\n",
      "Epoch: 73/100 Iteration: 729 Training loss: 0.00187\n",
      "Epoch: 72/100 Iteration: 730 Validation Acc: 0.8136\n",
      "Epoch: 74/100 Iteration: 730 Training loss: 0.00160\n",
      "Epoch: 74/100 Iteration: 731 Training loss: 0.00152\n",
      "Epoch: 74/100 Iteration: 732 Training loss: 0.00157\n",
      "Epoch: 74/100 Iteration: 733 Training loss: 0.00176\n",
      "Epoch: 74/100 Iteration: 734 Training loss: 0.00184\n",
      "Epoch: 73/100 Iteration: 735 Validation Acc: 0.8136\n",
      "Epoch: 74/100 Iteration: 735 Training loss: 0.00175\n",
      "Epoch: 74/100 Iteration: 736 Training loss: 0.00203\n",
      "Epoch: 74/100 Iteration: 737 Training loss: 0.00184\n",
      "Epoch: 74/100 Iteration: 738 Training loss: 0.00173\n",
      "Epoch: 74/100 Iteration: 739 Training loss: 0.00184\n",
      "Epoch: 73/100 Iteration: 740 Validation Acc: 0.8136\n",
      "Epoch: 75/100 Iteration: 740 Training loss: 0.00157\n",
      "Epoch: 75/100 Iteration: 741 Training loss: 0.00149\n",
      "Epoch: 75/100 Iteration: 742 Training loss: 0.00154\n",
      "Epoch: 75/100 Iteration: 743 Training loss: 0.00172\n",
      "Epoch: 75/100 Iteration: 744 Training loss: 0.00180\n",
      "Epoch: 74/100 Iteration: 745 Validation Acc: 0.8136\n",
      "Epoch: 75/100 Iteration: 745 Training loss: 0.00171\n",
      "Epoch: 75/100 Iteration: 746 Training loss: 0.00199\n",
      "Epoch: 75/100 Iteration: 747 Training loss: 0.00180\n",
      "Epoch: 75/100 Iteration: 748 Training loss: 0.00170\n",
      "Epoch: 75/100 Iteration: 749 Training loss: 0.00180\n",
      "Epoch: 74/100 Iteration: 750 Validation Acc: 0.8136\n",
      "Epoch: 76/100 Iteration: 750 Training loss: 0.00154\n",
      "Epoch: 76/100 Iteration: 751 Training loss: 0.00146\n",
      "Epoch: 76/100 Iteration: 752 Training loss: 0.00151\n",
      "Epoch: 76/100 Iteration: 753 Training loss: 0.00168\n",
      "Epoch: 76/100 Iteration: 754 Training loss: 0.00176\n",
      "Epoch: 75/100 Iteration: 755 Validation Acc: 0.8136\n",
      "Epoch: 76/100 Iteration: 755 Training loss: 0.00168\n",
      "Epoch: 76/100 Iteration: 756 Training loss: 0.00195\n",
      "Epoch: 76/100 Iteration: 757 Training loss: 0.00176\n",
      "Epoch: 76/100 Iteration: 758 Training loss: 0.00166\n",
      "Epoch: 76/100 Iteration: 759 Training loss: 0.00176\n",
      "Epoch: 75/100 Iteration: 760 Validation Acc: 0.8136\n",
      "Epoch: 77/100 Iteration: 760 Training loss: 0.00150\n",
      "Epoch: 77/100 Iteration: 761 Training loss: 0.00143\n",
      "Epoch: 77/100 Iteration: 762 Training loss: 0.00148\n",
      "Epoch: 77/100 Iteration: 763 Training loss: 0.00165\n",
      "Epoch: 77/100 Iteration: 764 Training loss: 0.00173\n",
      "Epoch: 76/100 Iteration: 765 Validation Acc: 0.8136\n",
      "Epoch: 77/100 Iteration: 765 Training loss: 0.00164\n",
      "Epoch: 77/100 Iteration: 766 Training loss: 0.00191\n",
      "Epoch: 77/100 Iteration: 767 Training loss: 0.00172\n",
      "Epoch: 77/100 Iteration: 768 Training loss: 0.00163\n",
      "Epoch: 77/100 Iteration: 769 Training loss: 0.00172\n",
      "Epoch: 76/100 Iteration: 770 Validation Acc: 0.8136\n",
      "Epoch: 78/100 Iteration: 770 Training loss: 0.00147\n",
      "Epoch: 78/100 Iteration: 771 Training loss: 0.00140\n",
      "Epoch: 78/100 Iteration: 772 Training loss: 0.00145\n",
      "Epoch: 78/100 Iteration: 773 Training loss: 0.00161\n",
      "Epoch: 78/100 Iteration: 774 Training loss: 0.00169\n",
      "Epoch: 77/100 Iteration: 775 Validation Acc: 0.8136\n",
      "Epoch: 78/100 Iteration: 775 Training loss: 0.00161\n",
      "Epoch: 78/100 Iteration: 776 Training loss: 0.00186\n",
      "Epoch: 78/100 Iteration: 777 Training loss: 0.00169\n",
      "Epoch: 78/100 Iteration: 778 Training loss: 0.00160\n",
      "Epoch: 78/100 Iteration: 779 Training loss: 0.00169\n",
      "Epoch: 77/100 Iteration: 780 Validation Acc: 0.8136\n",
      "Epoch: 79/100 Iteration: 780 Training loss: 0.00144\n",
      "Epoch: 79/100 Iteration: 781 Training loss: 0.00137\n",
      "Epoch: 79/100 Iteration: 782 Training loss: 0.00142\n",
      "Epoch: 79/100 Iteration: 783 Training loss: 0.00158\n",
      "Epoch: 79/100 Iteration: 784 Training loss: 0.00165\n",
      "Epoch: 78/100 Iteration: 785 Validation Acc: 0.8136\n",
      "Epoch: 79/100 Iteration: 785 Training loss: 0.00157\n",
      "Epoch: 79/100 Iteration: 786 Training loss: 0.00183\n",
      "Epoch: 79/100 Iteration: 787 Training loss: 0.00166\n",
      "Epoch: 79/100 Iteration: 788 Training loss: 0.00157\n",
      "Epoch: 79/100 Iteration: 789 Training loss: 0.00166\n",
      "Epoch: 78/100 Iteration: 790 Validation Acc: 0.8136\n",
      "Epoch: 80/100 Iteration: 790 Training loss: 0.00141\n",
      "Epoch: 80/100 Iteration: 791 Training loss: 0.00135\n",
      "Epoch: 80/100 Iteration: 792 Training loss: 0.00139\n",
      "Epoch: 80/100 Iteration: 793 Training loss: 0.00155\n",
      "Epoch: 80/100 Iteration: 794 Training loss: 0.00162\n",
      "Epoch: 79/100 Iteration: 795 Validation Acc: 0.8136\n",
      "Epoch: 80/100 Iteration: 795 Training loss: 0.00154\n",
      "Epoch: 80/100 Iteration: 796 Training loss: 0.00179\n",
      "Epoch: 80/100 Iteration: 797 Training loss: 0.00162\n",
      "Epoch: 80/100 Iteration: 798 Training loss: 0.00154\n",
      "Epoch: 80/100 Iteration: 799 Training loss: 0.00162\n",
      "Epoch: 79/100 Iteration: 800 Validation Acc: 0.8136\n",
      "Epoch: 81/100 Iteration: 800 Training loss: 0.00139\n",
      "Epoch: 81/100 Iteration: 801 Training loss: 0.00132\n",
      "Epoch: 81/100 Iteration: 802 Training loss: 0.00136\n",
      "Epoch: 81/100 Iteration: 803 Training loss: 0.00152\n",
      "Epoch: 81/100 Iteration: 804 Training loss: 0.00159\n",
      "Epoch: 80/100 Iteration: 805 Validation Acc: 0.8136\n",
      "Epoch: 81/100 Iteration: 805 Training loss: 0.00151\n",
      "Epoch: 81/100 Iteration: 806 Training loss: 0.00176\n",
      "Epoch: 81/100 Iteration: 807 Training loss: 0.00159\n",
      "Epoch: 81/100 Iteration: 808 Training loss: 0.00151\n",
      "Epoch: 81/100 Iteration: 809 Training loss: 0.00159\n",
      "Epoch: 80/100 Iteration: 810 Validation Acc: 0.8136\n",
      "Epoch: 82/100 Iteration: 810 Training loss: 0.00136\n",
      "Epoch: 82/100 Iteration: 811 Training loss: 0.00129\n",
      "Epoch: 82/100 Iteration: 812 Training loss: 0.00134\n",
      "Epoch: 82/100 Iteration: 813 Training loss: 0.00149\n",
      "Epoch: 82/100 Iteration: 814 Training loss: 0.00156\n",
      "Epoch: 81/100 Iteration: 815 Validation Acc: 0.8136\n",
      "Epoch: 82/100 Iteration: 815 Training loss: 0.00148\n",
      "Epoch: 82/100 Iteration: 816 Training loss: 0.00172\n",
      "Epoch: 82/100 Iteration: 817 Training loss: 0.00156\n",
      "Epoch: 82/100 Iteration: 818 Training loss: 0.00148\n",
      "Epoch: 82/100 Iteration: 819 Training loss: 0.00156\n",
      "Epoch: 81/100 Iteration: 820 Validation Acc: 0.8136\n",
      "Epoch: 83/100 Iteration: 820 Training loss: 0.00133\n",
      "Epoch: 83/100 Iteration: 821 Training loss: 0.00127\n",
      "Epoch: 83/100 Iteration: 822 Training loss: 0.00131\n",
      "Epoch: 83/100 Iteration: 823 Training loss: 0.00146\n",
      "Epoch: 83/100 Iteration: 824 Training loss: 0.00153\n",
      "Epoch: 82/100 Iteration: 825 Validation Acc: 0.8136\n",
      "Epoch: 83/100 Iteration: 825 Training loss: 0.00146\n",
      "Epoch: 83/100 Iteration: 826 Training loss: 0.00169\n",
      "Epoch: 83/100 Iteration: 827 Training loss: 0.00153\n",
      "Epoch: 83/100 Iteration: 828 Training loss: 0.00145\n",
      "Epoch: 83/100 Iteration: 829 Training loss: 0.00153\n",
      "Epoch: 82/100 Iteration: 830 Validation Acc: 0.8136\n",
      "Epoch: 84/100 Iteration: 830 Training loss: 0.00130\n",
      "Epoch: 84/100 Iteration: 831 Training loss: 0.00124\n",
      "Epoch: 84/100 Iteration: 832 Training loss: 0.00128\n",
      "Epoch: 84/100 Iteration: 833 Training loss: 0.00143\n",
      "Epoch: 84/100 Iteration: 834 Training loss: 0.00150\n",
      "Epoch: 83/100 Iteration: 835 Validation Acc: 0.8136\n",
      "Epoch: 84/100 Iteration: 835 Training loss: 0.00143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100 Iteration: 836 Training loss: 0.00165\n",
      "Epoch: 84/100 Iteration: 837 Training loss: 0.00150\n",
      "Epoch: 84/100 Iteration: 838 Training loss: 0.00142\n",
      "Epoch: 84/100 Iteration: 839 Training loss: 0.00150\n",
      "Epoch: 83/100 Iteration: 840 Validation Acc: 0.8136\n",
      "Epoch: 85/100 Iteration: 840 Training loss: 0.00128\n",
      "Epoch: 85/100 Iteration: 841 Training loss: 0.00122\n",
      "Epoch: 85/100 Iteration: 842 Training loss: 0.00126\n",
      "Epoch: 85/100 Iteration: 843 Training loss: 0.00141\n",
      "Epoch: 85/100 Iteration: 844 Training loss: 0.00147\n",
      "Epoch: 84/100 Iteration: 845 Validation Acc: 0.8136\n",
      "Epoch: 85/100 Iteration: 845 Training loss: 0.00140\n",
      "Epoch: 85/100 Iteration: 846 Training loss: 0.00162\n",
      "Epoch: 85/100 Iteration: 847 Training loss: 0.00147\n",
      "Epoch: 85/100 Iteration: 848 Training loss: 0.00140\n",
      "Epoch: 85/100 Iteration: 849 Training loss: 0.00147\n",
      "Epoch: 84/100 Iteration: 850 Validation Acc: 0.8136\n",
      "Epoch: 86/100 Iteration: 850 Training loss: 0.00126\n",
      "Epoch: 86/100 Iteration: 851 Training loss: 0.00120\n",
      "Epoch: 86/100 Iteration: 852 Training loss: 0.00124\n",
      "Epoch: 86/100 Iteration: 853 Training loss: 0.00138\n",
      "Epoch: 86/100 Iteration: 854 Training loss: 0.00144\n",
      "Epoch: 85/100 Iteration: 855 Validation Acc: 0.8136\n",
      "Epoch: 86/100 Iteration: 855 Training loss: 0.00138\n",
      "Epoch: 86/100 Iteration: 856 Training loss: 0.00159\n",
      "Epoch: 86/100 Iteration: 857 Training loss: 0.00144\n",
      "Epoch: 86/100 Iteration: 858 Training loss: 0.00137\n",
      "Epoch: 86/100 Iteration: 859 Training loss: 0.00144\n",
      "Epoch: 85/100 Iteration: 860 Validation Acc: 0.8136\n",
      "Epoch: 87/100 Iteration: 860 Training loss: 0.00123\n",
      "Epoch: 87/100 Iteration: 861 Training loss: 0.00118\n",
      "Epoch: 87/100 Iteration: 862 Training loss: 0.00121\n",
      "Epoch: 87/100 Iteration: 863 Training loss: 0.00135\n",
      "Epoch: 87/100 Iteration: 864 Training loss: 0.00141\n",
      "Epoch: 86/100 Iteration: 865 Validation Acc: 0.8136\n",
      "Epoch: 87/100 Iteration: 865 Training loss: 0.00135\n",
      "Epoch: 87/100 Iteration: 866 Training loss: 0.00156\n",
      "Epoch: 87/100 Iteration: 867 Training loss: 0.00142\n",
      "Epoch: 87/100 Iteration: 868 Training loss: 0.00135\n",
      "Epoch: 87/100 Iteration: 869 Training loss: 0.00142\n",
      "Epoch: 86/100 Iteration: 870 Validation Acc: 0.8136\n",
      "Epoch: 88/100 Iteration: 870 Training loss: 0.00121\n",
      "Epoch: 88/100 Iteration: 871 Training loss: 0.00115\n",
      "Epoch: 88/100 Iteration: 872 Training loss: 0.00119\n",
      "Epoch: 88/100 Iteration: 873 Training loss: 0.00133\n",
      "Epoch: 88/100 Iteration: 874 Training loss: 0.00139\n",
      "Epoch: 87/100 Iteration: 875 Validation Acc: 0.8136\n",
      "Epoch: 88/100 Iteration: 875 Training loss: 0.00132\n",
      "Epoch: 88/100 Iteration: 876 Training loss: 0.00153\n",
      "Epoch: 88/100 Iteration: 877 Training loss: 0.00139\n",
      "Epoch: 88/100 Iteration: 878 Training loss: 0.00132\n",
      "Epoch: 88/100 Iteration: 879 Training loss: 0.00139\n",
      "Epoch: 87/100 Iteration: 880 Validation Acc: 0.8136\n",
      "Epoch: 89/100 Iteration: 880 Training loss: 0.00119\n",
      "Epoch: 89/100 Iteration: 881 Training loss: 0.00113\n",
      "Epoch: 89/100 Iteration: 882 Training loss: 0.00117\n",
      "Epoch: 89/100 Iteration: 883 Training loss: 0.00130\n",
      "Epoch: 89/100 Iteration: 884 Training loss: 0.00136\n",
      "Epoch: 88/100 Iteration: 885 Validation Acc: 0.8136\n",
      "Epoch: 89/100 Iteration: 885 Training loss: 0.00130\n",
      "Epoch: 89/100 Iteration: 886 Training loss: 0.00150\n",
      "Epoch: 89/100 Iteration: 887 Training loss: 0.00136\n",
      "Epoch: 89/100 Iteration: 888 Training loss: 0.00130\n",
      "Epoch: 89/100 Iteration: 889 Training loss: 0.00136\n",
      "Epoch: 88/100 Iteration: 890 Validation Acc: 0.8136\n",
      "Epoch: 90/100 Iteration: 890 Training loss: 0.00116\n",
      "Epoch: 90/100 Iteration: 891 Training loss: 0.00111\n",
      "Epoch: 90/100 Iteration: 892 Training loss: 0.00115\n",
      "Epoch: 90/100 Iteration: 893 Training loss: 0.00128\n",
      "Epoch: 90/100 Iteration: 894 Training loss: 0.00134\n",
      "Epoch: 89/100 Iteration: 895 Validation Acc: 0.8136\n",
      "Epoch: 90/100 Iteration: 895 Training loss: 0.00128\n",
      "Epoch: 90/100 Iteration: 896 Training loss: 0.00147\n",
      "Epoch: 90/100 Iteration: 897 Training loss: 0.00134\n",
      "Epoch: 90/100 Iteration: 898 Training loss: 0.00127\n",
      "Epoch: 90/100 Iteration: 899 Training loss: 0.00134\n",
      "Epoch: 89/100 Iteration: 900 Validation Acc: 0.8136\n",
      "Epoch: 91/100 Iteration: 900 Training loss: 0.00114\n",
      "Epoch: 91/100 Iteration: 901 Training loss: 0.00109\n",
      "Epoch: 91/100 Iteration: 902 Training loss: 0.00113\n",
      "Epoch: 91/100 Iteration: 903 Training loss: 0.00126\n",
      "Epoch: 91/100 Iteration: 904 Training loss: 0.00131\n",
      "Epoch: 90/100 Iteration: 905 Validation Acc: 0.8136\n",
      "Epoch: 91/100 Iteration: 905 Training loss: 0.00125\n",
      "Epoch: 91/100 Iteration: 906 Training loss: 0.00145\n",
      "Epoch: 91/100 Iteration: 907 Training loss: 0.00131\n",
      "Epoch: 91/100 Iteration: 908 Training loss: 0.00125\n",
      "Epoch: 91/100 Iteration: 909 Training loss: 0.00131\n",
      "Epoch: 90/100 Iteration: 910 Validation Acc: 0.8136\n",
      "Epoch: 92/100 Iteration: 910 Training loss: 0.00112\n",
      "Epoch: 92/100 Iteration: 911 Training loss: 0.00107\n",
      "Epoch: 92/100 Iteration: 912 Training loss: 0.00111\n",
      "Epoch: 92/100 Iteration: 913 Training loss: 0.00123\n",
      "Epoch: 92/100 Iteration: 914 Training loss: 0.00129\n",
      "Epoch: 91/100 Iteration: 915 Validation Acc: 0.8136\n",
      "Epoch: 92/100 Iteration: 915 Training loss: 0.00123\n",
      "Epoch: 92/100 Iteration: 916 Training loss: 0.00142\n",
      "Epoch: 92/100 Iteration: 917 Training loss: 0.00129\n",
      "Epoch: 92/100 Iteration: 918 Training loss: 0.00123\n",
      "Epoch: 92/100 Iteration: 919 Training loss: 0.00129\n",
      "Epoch: 91/100 Iteration: 920 Validation Acc: 0.8136\n",
      "Epoch: 93/100 Iteration: 920 Training loss: 0.00110\n",
      "Epoch: 93/100 Iteration: 921 Training loss: 0.00105\n",
      "Epoch: 93/100 Iteration: 922 Training loss: 0.00109\n",
      "Epoch: 93/100 Iteration: 923 Training loss: 0.00121\n",
      "Epoch: 93/100 Iteration: 924 Training loss: 0.00127\n",
      "Epoch: 92/100 Iteration: 925 Validation Acc: 0.8136\n",
      "Epoch: 93/100 Iteration: 925 Training loss: 0.00121\n",
      "Epoch: 93/100 Iteration: 926 Training loss: 0.00140\n",
      "Epoch: 93/100 Iteration: 927 Training loss: 0.00127\n",
      "Epoch: 93/100 Iteration: 928 Training loss: 0.00121\n",
      "Epoch: 93/100 Iteration: 929 Training loss: 0.00127\n",
      "Epoch: 92/100 Iteration: 930 Validation Acc: 0.8136\n",
      "Epoch: 94/100 Iteration: 930 Training loss: 0.00108\n",
      "Epoch: 94/100 Iteration: 931 Training loss: 0.00104\n",
      "Epoch: 94/100 Iteration: 932 Training loss: 0.00107\n",
      "Epoch: 94/100 Iteration: 933 Training loss: 0.00119\n",
      "Epoch: 94/100 Iteration: 934 Training loss: 0.00124\n",
      "Epoch: 93/100 Iteration: 935 Validation Acc: 0.8136\n",
      "Epoch: 94/100 Iteration: 935 Training loss: 0.00119\n",
      "Epoch: 94/100 Iteration: 936 Training loss: 0.00137\n",
      "Epoch: 94/100 Iteration: 937 Training loss: 0.00124\n",
      "Epoch: 94/100 Iteration: 938 Training loss: 0.00119\n",
      "Epoch: 94/100 Iteration: 939 Training loss: 0.00124\n",
      "Epoch: 93/100 Iteration: 940 Validation Acc: 0.8136\n",
      "Epoch: 95/100 Iteration: 940 Training loss: 0.00106\n",
      "Epoch: 95/100 Iteration: 941 Training loss: 0.00102\n",
      "Epoch: 95/100 Iteration: 942 Training loss: 0.00105\n",
      "Epoch: 95/100 Iteration: 943 Training loss: 0.00117\n",
      "Epoch: 95/100 Iteration: 944 Training loss: 0.00122\n",
      "Epoch: 94/100 Iteration: 945 Validation Acc: 0.8136\n",
      "Epoch: 95/100 Iteration: 945 Training loss: 0.00117\n",
      "Epoch: 95/100 Iteration: 946 Training loss: 0.00135\n",
      "Epoch: 95/100 Iteration: 947 Training loss: 0.00122\n",
      "Epoch: 95/100 Iteration: 948 Training loss: 0.00117\n",
      "Epoch: 95/100 Iteration: 949 Training loss: 0.00122\n",
      "Epoch: 94/100 Iteration: 950 Validation Acc: 0.8136\n",
      "Epoch: 96/100 Iteration: 950 Training loss: 0.00105\n",
      "Epoch: 96/100 Iteration: 951 Training loss: 0.00100\n",
      "Epoch: 96/100 Iteration: 952 Training loss: 0.00103\n",
      "Epoch: 96/100 Iteration: 953 Training loss: 0.00115\n",
      "Epoch: 96/100 Iteration: 954 Training loss: 0.00120\n",
      "Epoch: 95/100 Iteration: 955 Validation Acc: 0.8156\n",
      "Epoch: 96/100 Iteration: 955 Training loss: 0.00115\n",
      "Epoch: 96/100 Iteration: 956 Training loss: 0.00132\n",
      "Epoch: 96/100 Iteration: 957 Training loss: 0.00120\n",
      "Epoch: 96/100 Iteration: 958 Training loss: 0.00115\n",
      "Epoch: 96/100 Iteration: 959 Training loss: 0.00120\n",
      "Epoch: 95/100 Iteration: 960 Validation Acc: 0.8136\n",
      "Epoch: 97/100 Iteration: 960 Training loss: 0.00103\n",
      "Epoch: 97/100 Iteration: 961 Training loss: 0.00098\n",
      "Epoch: 97/100 Iteration: 962 Training loss: 0.00102\n",
      "Epoch: 97/100 Iteration: 963 Training loss: 0.00113\n",
      "Epoch: 97/100 Iteration: 964 Training loss: 0.00118\n",
      "Epoch: 96/100 Iteration: 965 Validation Acc: 0.8156\n",
      "Epoch: 97/100 Iteration: 965 Training loss: 0.00113\n",
      "Epoch: 97/100 Iteration: 966 Training loss: 0.00130\n",
      "Epoch: 97/100 Iteration: 967 Training loss: 0.00118\n",
      "Epoch: 97/100 Iteration: 968 Training loss: 0.00113\n",
      "Epoch: 97/100 Iteration: 969 Training loss: 0.00118\n",
      "Epoch: 96/100 Iteration: 970 Validation Acc: 0.8156\n",
      "Epoch: 98/100 Iteration: 970 Training loss: 0.00101\n",
      "Epoch: 98/100 Iteration: 971 Training loss: 0.00097\n",
      "Epoch: 98/100 Iteration: 972 Training loss: 0.00100\n",
      "Epoch: 98/100 Iteration: 973 Training loss: 0.00111\n",
      "Epoch: 98/100 Iteration: 974 Training loss: 0.00116\n",
      "Epoch: 97/100 Iteration: 975 Validation Acc: 0.8156\n",
      "Epoch: 98/100 Iteration: 975 Training loss: 0.00111\n",
      "Epoch: 98/100 Iteration: 976 Training loss: 0.00128\n",
      "Epoch: 98/100 Iteration: 977 Training loss: 0.00116\n",
      "Epoch: 98/100 Iteration: 978 Training loss: 0.00111\n",
      "Epoch: 98/100 Iteration: 979 Training loss: 0.00116\n",
      "Epoch: 97/100 Iteration: 980 Validation Acc: 0.8156\n",
      "Epoch: 99/100 Iteration: 980 Training loss: 0.00099\n",
      "Epoch: 99/100 Iteration: 981 Training loss: 0.00095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 Iteration: 982 Training loss: 0.00098\n",
      "Epoch: 99/100 Iteration: 983 Training loss: 0.00109\n",
      "Epoch: 99/100 Iteration: 984 Training loss: 0.00114\n",
      "Epoch: 98/100 Iteration: 985 Validation Acc: 0.8156\n",
      "Epoch: 99/100 Iteration: 985 Training loss: 0.00109\n",
      "Epoch: 99/100 Iteration: 986 Training loss: 0.00125\n",
      "Epoch: 99/100 Iteration: 987 Training loss: 0.00114\n",
      "Epoch: 99/100 Iteration: 988 Training loss: 0.00109\n",
      "Epoch: 99/100 Iteration: 989 Training loss: 0.00114\n",
      "Epoch: 98/100 Iteration: 990 Validation Acc: 0.8156\n",
      "Epoch: 100/100 Iteration: 990 Training loss: 0.00098\n",
      "Epoch: 100/100 Iteration: 991 Training loss: 0.00093\n",
      "Epoch: 100/100 Iteration: 992 Training loss: 0.00097\n",
      "Epoch: 100/100 Iteration: 993 Training loss: 0.00107\n",
      "Epoch: 100/100 Iteration: 994 Training loss: 0.00112\n",
      "Epoch: 99/100 Iteration: 995 Validation Acc: 0.8156\n",
      "Epoch: 100/100 Iteration: 995 Training loss: 0.00107\n",
      "Epoch: 100/100 Iteration: 996 Training loss: 0.00123\n",
      "Epoch: 100/100 Iteration: 997 Training loss: 0.00112\n",
      "Epoch: 100/100 Iteration: 998 Training loss: 0.00107\n",
      "Epoch: 100/100 Iteration: 999 Training loss: 0.00112\n",
      "Epoch: 99/100 Iteration: 1000 Validation Acc: 0.8156\n"
     ]
    }
   ],
   "source": [
    "# 运行多少轮次\n",
    "epochs = 100\n",
    "# 统计训练效果的频率\n",
    "iteration = 0\n",
    "# 保存模型的保存器\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            # 训练模型\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x,\n",
    "                        labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                # 输出用验证机验证训练进度\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    # 保存模型\n",
    "    saver.save(sess, \"checkpoints/cif.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\cif.ckpt\n",
      "Test accuracy: 0.8360\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
